{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bd35227-bbbd-4de9-a08d-b88d602f6313",
   "metadata": {},
   "source": [
    "<img align='left' src = '../images/linea.png' width=150 style='padding: 20px'> \n",
    "\n",
    "# DP02 duplicates analysis\n",
    "## Part 2 - Analysis of two subsamples, one with even tracts and other with odd tracts\n",
    "\n",
    "Analysis of duplicates found in the DP02 catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3c4dd9-452d-47d4-a883-0e2fab41592c",
   "metadata": {},
   "source": [
    "Contacts: Luigi Silva ([luigi.silva@linea.org.br](mailto:luigi.silva@linea.org.br)); Julia Gschwend ([julia@linea.org.br](mailto:julia@linea.org.br)).\n",
    "\n",
    "Last check: 03/10/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66374531-4e54-4352-a511-cbf08689d14a",
   "metadata": {},
   "source": [
    "#### Acknowledgments\n",
    "\n",
    "'_This notebook used computational resources from the Associação Laboratório Interinstitucional de e-Astronomia (LIneA) with financial support from the INCT of e-Universe (Process No. 465376/2014-2)._'\n",
    "\n",
    "'_This notebook uses libraries from the LSST Interdisciplinary Network for Collaboration and Computing (LINCC) Frameworks project, such as the hipscat, hipscat_import, and lsdb libraries. The LINCC Frameworks project is supported by Schmidt Sciences. It is also based on work supported by the National Science Foundation under Grant No. AST-2003196. Additionally, it receives support from the DIRAC Institute at the Department of Astronomy of the University of Washington. The DIRAC Institute is supported by gifts from the Charles and Lisa Simonyi Fund for Arts and Sciences and the Washington Research Foundation._'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bdc6a4-01e6-4e8c-8e7e-5fd09d9f7571",
   "metadata": {},
   "source": [
    "# Imports and Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4ca91a-a568-4d2a-87f5-2147fb03f0ef",
   "metadata": {},
   "source": [
    "Let us import the packages that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfea3ff2-a828-4255-9218-4df493c014c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### GENERAL ##########################\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import getpass\n",
    "import warnings\n",
    "import tables_io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "############################ DASK ############################\n",
    "from dask import dataframe as dd\n",
    "from dask import delayed\n",
    "from dask.distributed import Client, performance_report\n",
    "from dask_jobqueue import SLURMCluster\n",
    "########################## HIPSCAT ###########################\n",
    "import hipscat\n",
    "from hipscat.catalog import Catalog\n",
    "from hipscat.inspection import plot_pixels\n",
    "from hipscat_import.catalog.file_readers import ParquetReader\n",
    "from hipscat_import.margin_cache.margin_cache_arguments import MarginCacheArguments\n",
    "from hipscat_import.pipeline import ImportArguments, pipeline_with_client\n",
    "############################ LSDB ############################\n",
    "import lsdb\n",
    "######################## VISUALIZATION #######################\n",
    "### BOKEH\n",
    "import bokeh\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.models import ColorBar, LinearColorMapper\n",
    "from bokeh.palettes import Viridis256\n",
    "\n",
    "### HOLOVIEWS\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "from holoviews.operation.datashader import rasterize, dynspread\n",
    "\n",
    "### GEOVIEWS\n",
    "import geoviews as gv\n",
    "import geoviews.feature as gf\n",
    "from cartopy import crs\n",
    "\n",
    "### DATASHADER\n",
    "import datashader as ds\n",
    "\n",
    "### MATPLOTLIB\n",
    "import matplotlib.pyplot as plt\n",
    "########################## ASTRONOMY #########################\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.units.quantity import Quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d644873-198f-4a75-8789-c5c08dcbf1aa",
   "metadata": {},
   "source": [
    "Now, let us configure the plots to be inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38016951-6bd4-427d-8fb2-a7825b8d8971",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('bokeh')\n",
    "gv.extension('bokeh')\n",
    "output_notebook()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b90445-8415-4583-baaa-4df642ce01f9",
   "metadata": {},
   "source": [
    "Now, let us define the paths to save the logs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fa3152-7d29-4ba4-8597-6ba753c09aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = getpass.getuser()\n",
    "base_path = f'/lustre/t0/scratch/users/{user}/report_hipscat/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53e900b-806e-4d16-9cb4-541752abfc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(base_path, 'output')\n",
    "logs_dir = os.path.join(base_path, 'logs')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(logs_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd65540-36de-4bf2-9e8a-e79c2996182d",
   "metadata": {},
   "source": [
    "Then, let us define the parameters for the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a622d2-b688-44fe-afd9-66b4cbd391a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring the SLURMCluster.\n",
    "cluster = SLURMCluster(\n",
    "    interface=\"ib0\",    # Lustre interface\n",
    "    queue='cpu_small',  # Name of the queue\n",
    "    cores=52,           # Number of logical cores per node\n",
    "    processes=13,       # Number of dask processes per node\n",
    "    memory='120GB',     # Memory per node\n",
    "    walltime='06:00:00',  # Maximum execution time\n",
    "    job_extra_directives=[\n",
    "        '--propagate',\n",
    "        f'--output={output_dir}/dask_job_%j.out',  \n",
    "        f'--error={output_dir}/dask_job_%j.err'\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Scaling the cluster to use X nodes\n",
    "cluster.scale(jobs=6)\n",
    "\n",
    "# Defining the dask client\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706cc3ba-0967-421f-a077-e5d93dca9f67",
   "metadata": {},
   "source": [
    "# Getting the paths of the files corresponding to the subsamples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa5061b-9401-465b-b3d1-0928473220cd",
   "metadata": {},
   "source": [
    "We want to define two subsamples from the DP02 files, one containing just even tracts and the other containing just odd tracts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbe75b1-b44d-4f71-9f48-317ff840a68e",
   "metadata": {},
   "source": [
    "Before getting the paths for the files corresponding to each subsample, let us show how many parquet files do we have in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468ed6dd-240c-4d76-a955-0351ec361378",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/lustre/t1/cl/lsst/dp02/primary/catalogs/object/*.parq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e980e8d5-b032-47c6-9925-e1672d0a3612",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_files = [f for f in glob.glob(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565cd483-cf0b-41aa-a6a8-b22f00aab626",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_files[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc7c888-8cf8-4250-ab57-7b7dfb23970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(total_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3b1b9a-1433-4f4e-b02b-1e69fc350ba3",
   "metadata": {},
   "source": [
    "## First subsample - Paths of even tracts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39a921d-895b-447c-8bd3-61d87e24e245",
   "metadata": {},
   "source": [
    "Now, let us get only the paths of even tracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a580a229-f65e-46bd-b84b-b4d7f2ca424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_even = [os.path.basename(f) for f in glob.glob(path) if re.search(r'tract_(\\d+)', f) and int(re.search(r'tract_(\\d+)', f).group(1)) % 2 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa93da3e-e937-446f-9259-458ccc3ef9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_even[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed157fb-15a0-46c0-ad16-86c45e0a3844",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files_even)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e09c448-31e9-437b-abbc-162f11d709c2",
   "metadata": {},
   "source": [
    "## Second subsample - Paths of odd tracts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae493b65-076f-4419-8b53-0008b43c2b46",
   "metadata": {},
   "source": [
    "Here, we get only the paths of odd tracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac253744-2f83-4fed-b869-4c1ec70e8086",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_odd = [os.path.basename(f) for f in glob.glob(path) if re.search(r'tract_(\\d+)', f) and int(re.search(r'tract_(\\d+)', f).group(1)) % 2 != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fd591e-0210-43cd-a3d8-9242c92f8667",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_odd[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1761ff-565d-4c4e-ac5f-21b8d608833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files_odd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87f2b1b-f14c-4d93-b126-6ce4c334f4c5",
   "metadata": {},
   "source": [
    "# Converting the subsamples to HiPSCat format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c71631-7315-404e-bd98-a993821e454c",
   "metadata": {},
   "source": [
    "## Converting the first subsample (even tracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dd503d-7818-40e2-8942-5b362b4c90b8",
   "metadata": {},
   "source": [
    "Generating the HiPSCat catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aed5e9-21db-40bb-9129-f1e9935f3dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO YOU WANT TO RUN THE PIPELINE? SET FALSE IF YOU ALREADY GENERATED THE HIPSCAT CATALOG.\n",
    "run_the_pipeline = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747c3ef6-5961-4223-9f47-4fdea944930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## INPUT CONFIGS #################################\n",
    "### Directory and name of the input files. The name can be a list or contain a wildcard, ex: files_*.parquet.\n",
    "CATALOG_DIR = Path('/lustre/t1/cl/lsst/dp02/primary/catalogs/object/')\n",
    "CATALOG_FILES = files_even\n",
    "### Columns to be selected in the input files. The id, ra e dec columns are essential.\n",
    "CATALOG_SELECTED_COLUMNS = ['objectId', 'coord_ra', 'coord_dec', 'u_cModelFlux', 'g_cModelFlux', 'r_cModelFlux', 'i_cModelFlux', \n",
    "                            'z_cModelFlux', 'y_cModelFlux', 'u_cModelFluxErr', 'g_cModelFluxErr', 'r_cModelFluxErr', 'i_cModelFluxErr', \n",
    "                            'z_cModelFluxErr', 'y_cModelFluxErr', 'detect_isPrimary']\n",
    "CATALOG_SORT_COLUMN = 'objectId'\n",
    "CATALOG_RA_COLUMN = 'coord_ra'\n",
    "CATALOG_DEC_COLUMN = 'coord_dec'\n",
    "### Type of the files we will read.\n",
    "FILE_TYPE = 'parquet'\n",
    "### Name of the HiPSCat catalog to be saved.\n",
    "CATALOG_HIPSCAT_NAME = 'DP02_object_even_tracts'\n",
    "###########################################################################################\n",
    "\n",
    "################################# OUTPUT CONFIGS #################################\n",
    "### Output directory for the catalogs.\n",
    "OUTPUT_DIR = Path(output_dir)\n",
    "HIPSCAT_DIR_NAME = 'hipscat'\n",
    "HIPSCAT_DIR = OUTPUT_DIR / HIPSCAT_DIR_NAME\n",
    "\n",
    "CATALOG_HIPSCAT_DIR = HIPSCAT_DIR / CATALOG_HIPSCAT_NAME\n",
    "\n",
    "### Path to dask performance report.\n",
    "LOGS_DIR = Path(logs_dir) \n",
    "\n",
    "PERFORMANCE_REPORT_NAME = 'performance_report_make_hipscat_DP02_object_even.html'\n",
    "PERFORMANCE_DIR = LOGS_DIR / PERFORMANCE_REPORT_NAME\n",
    "###########################################################################################\n",
    "\n",
    "############################### EXECUTING THE PIPELINE ######################################\n",
    "if run_the_pipeline==True:\n",
    "    with performance_report(filename=PERFORMANCE_DIR):\n",
    "        if isinstance(CATALOG_FILES, list)==True:\n",
    "            CATALOG_PATHS = [CATALOG_DIR / file for file in CATALOG_FILES]\n",
    "        elif isinstance(CATALOG_FILES, str)==True:\n",
    "            CATALOG_PATHS = list(CATALOG_DIR.glob(CATALOG_FILES))\n",
    "        else:\n",
    "            raise Exception('The type of names of catalogs files (CATALOG_FILES) is not supported. Supported types are list and str.')\n",
    "    \n",
    "        if FILE_TYPE=='parquet':\n",
    "            catalog_args = ImportArguments(\n",
    "                sort_columns=CATALOG_SORT_COLUMN,\n",
    "                ra_column=CATALOG_RA_COLUMN,\n",
    "                dec_column=CATALOG_DEC_COLUMN,\n",
    "                input_file_list=CATALOG_PATHS,\n",
    "                file_reader=ParquetReader(column_names=CATALOG_SELECTED_COLUMNS),\n",
    "                output_artifact_name=CATALOG_HIPSCAT_NAME,\n",
    "                output_path=HIPSCAT_DIR,\n",
    "            )\n",
    "            pipeline_with_client(catalog_args, client)\n",
    "        else:\n",
    "            raise Exception('Input catalog type not supported yet.')\n",
    "else:\n",
    "    print('You selected not to run the pipeline.') \n",
    "###########################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0a12a8-eaaa-454b-b7b6-12324aa12774",
   "metadata": {},
   "source": [
    "Plotting the pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeba0bfa-8e05-445e-b657-d03b5823f520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the HiPSCat catalog metadata, it does not load any data, just healpix pixels and other metadata\n",
    "DP02_even_tracts_hipscat_catalog = Catalog.read_from_hipscat(CATALOG_HIPSCAT_DIR)\n",
    "plot_pixels(DP02_even_tracts_hipscat_catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9d10c0-1d16-4046-b31b-5b9c2ec1f7f8",
   "metadata": {},
   "source": [
    "Reading the catalog into a dask dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d836d1-c1ef-4ba8-b9f6-1065ab265a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DP02_even_tracts_from_disk = lsdb.read_hipscat(CATALOG_HIPSCAT_DIR)\n",
    "DP02_even_tracts_from_disk_delayed = DP02_even_tracts_from_disk.to_delayed()\n",
    "DP02_even_tracts_from_disk_ddf = dd.from_delayed(DP02_even_tracts_from_disk_delayed)\n",
    "\n",
    "print(CATALOG_HIPSCAT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22b4abb-ca05-45d6-a80a-00776c5de1ba",
   "metadata": {},
   "source": [
    "Plotting the first lines of the dataframe and the basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f844967-728c-441e-aad7-529db9c9c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "DP02_even_tracts_from_disk_ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caea4c8-9ac3-4206-9c54-b4f4d44cb616",
   "metadata": {},
   "outputs": [],
   "source": [
    "DP02_even_tracts_from_disk_ddf.describe().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977fdb5a-fce2-4844-9e60-35d6cf933656",
   "metadata": {},
   "source": [
    "## Converting the second subsample (odd tracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45d261d-8d9d-43d6-b5a3-765861ce9434",
   "metadata": {},
   "source": [
    "Generating the HiPSCat catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c815d3-1a10-4a18-913d-0657e069c4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO YOU WANT TO RUN THE PIPELINE? SET FALSE IF YOU ALREADY GENERATED THE HIPSCAT CATALOG.\n",
    "run_the_pipeline = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19929a9-5775-4320-aab5-2b21eb7ae44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## INPUT CONFIGS #################################\n",
    "### Directory and name of the input files. The name can be a list or contain a wildcard, ex: files_*.parquet.\n",
    "CATALOG_DIR = Path('/lustre/t1/cl/lsst/dp02/primary/catalogs/object/')\n",
    "CATALOG_FILES = files_odd\n",
    "### Columns to be selected in the input files. The id, ra e dec columns are essential.\n",
    "CATALOG_SELECTED_COLUMNS = ['objectId', 'coord_ra', 'coord_dec', 'u_cModelFlux', 'g_cModelFlux', 'r_cModelFlux', 'i_cModelFlux', \n",
    "                            'z_cModelFlux', 'y_cModelFlux', 'u_cModelFluxErr', 'g_cModelFluxErr', 'r_cModelFluxErr', 'i_cModelFluxErr', \n",
    "                            'z_cModelFluxErr', 'y_cModelFluxErr', 'detect_isPrimary']\n",
    "CATALOG_SORT_COLUMN = 'objectId'\n",
    "CATALOG_RA_COLUMN = 'coord_ra'\n",
    "CATALOG_DEC_COLUMN = 'coord_dec'\n",
    "### Type of the files we will read.\n",
    "FILE_TYPE = 'parquet'\n",
    "### Name of the HiPSCat catalog to be saved.\n",
    "CATALOG_HIPSCAT_NAME = 'DP02_object_odd_tracts'\n",
    "###########################################################################################\n",
    "\n",
    "################################# OUTPUT CONFIGS #################################\n",
    "### Output directory for the catalogs.\n",
    "OUTPUT_DIR = Path(output_dir)\n",
    "HIPSCAT_DIR_NAME = 'hipscat'\n",
    "HIPSCAT_DIR = OUTPUT_DIR / HIPSCAT_DIR_NAME\n",
    "\n",
    "CATALOG_HIPSCAT_DIR = HIPSCAT_DIR / CATALOG_HIPSCAT_NAME\n",
    "\n",
    "### Path to dask performance report.\n",
    "LOGS_DIR = Path(logs_dir) \n",
    "\n",
    "PERFORMANCE_REPORT_NAME = 'performance_report_make_hipscat_DP02_object_odd.html'\n",
    "PERFORMANCE_DIR = LOGS_DIR / PERFORMANCE_REPORT_NAME\n",
    "###########################################################################################\n",
    "\n",
    "############################### EXECUTING THE PIPELINE ######################################\n",
    "if run_the_pipeline==True:\n",
    "    with performance_report(filename=PERFORMANCE_DIR):\n",
    "        if isinstance(CATALOG_FILES, list)==True:\n",
    "            CATALOG_PATHS = [CATALOG_DIR / file for file in CATALOG_FILES]\n",
    "        elif isinstance(CATALOG_FILES, str)==True:\n",
    "            CATALOG_PATHS = list(CATALOG_DIR.glob(CATALOG_FILES))\n",
    "        else:\n",
    "            raise Exception('The type of names of catalogs files (CATALOG_FILES) is not supported. Supported types are list and str.')\n",
    "    \n",
    "        if FILE_TYPE=='parquet':\n",
    "            catalog_args = ImportArguments(\n",
    "                sort_columns=CATALOG_SORT_COLUMN,\n",
    "                ra_column=CATALOG_RA_COLUMN,\n",
    "                dec_column=CATALOG_DEC_COLUMN,\n",
    "                input_file_list=CATALOG_PATHS,\n",
    "                file_reader=ParquetReader(column_names=CATALOG_SELECTED_COLUMNS),\n",
    "                output_artifact_name=CATALOG_HIPSCAT_NAME,\n",
    "                output_path=HIPSCAT_DIR,\n",
    "            )\n",
    "            pipeline_with_client(catalog_args, client)\n",
    "        else:\n",
    "            raise Exception('Input catalog type not supported yet.')\n",
    "else:\n",
    "    print('You selected not to run the pipeline.') \n",
    "###########################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc97a1b-8388-4b59-bf03-e79fb549da14",
   "metadata": {},
   "source": [
    "Plotting the pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b31722-8430-4005-8e21-5f210edeac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the HiPSCat catalog metadata, it does not load any data, just healpix pixels and other metadata\n",
    "DP02_odd_tracts_hipscat_catalog = Catalog.read_from_hipscat(CATALOG_HIPSCAT_DIR)\n",
    "plot_pixels(DP02_odd_tracts_hipscat_catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c40ea7-71ad-4eec-a69c-f25c7cb82085",
   "metadata": {},
   "source": [
    "Reading the catalog into a dask dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f4a09b-8ef6-46ba-8f71-025260e40af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DP02_odd_tracts_from_disk = lsdb.read_hipscat(CATALOG_HIPSCAT_DIR)\n",
    "DP02_odd_tracts_from_disk_delayed = DP02_odd_tracts_from_disk.to_delayed()\n",
    "DP02_odd_tracts_from_disk_ddf = dd.from_delayed(DP02_odd_tracts_from_disk_delayed)\n",
    "\n",
    "print(CATALOG_HIPSCAT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314baaf8-5259-48cd-9920-d18e12857a2e",
   "metadata": {},
   "source": [
    "Plotting the first lines of the dataframe and the basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658d69da-4169-40f2-bdf8-ba8de3e2c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DP02_odd_tracts_from_disk_ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773bba71-c9df-47da-a56c-3338725fcbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "DP02_odd_tracts_from_disk_ddf.describe().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63594af3-3ac9-4c8e-ad38-f62ed4d98645",
   "metadata": {},
   "source": [
    "# Generating the margin cache for the second subsample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d140e355-7a24-4b69-967d-9610b3961f2a",
   "metadata": {},
   "source": [
    "Generating the margin cache for the odd tracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f96275-7c6f-4970-b0da-1dacf5315bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO YOU WANT TO RUN THE PIPELINE? SET FALSE IF YOU ALREADY GENERATED THE HIPSCAT CATALOG.\n",
    "run_the_pipeline = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3903971d-5089-4d7c-ad79-cc4024f964a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## INPUT CONFIGS #################################\n",
    "### Path of the input HiPSCat catalog.\n",
    "CATALOG_HIPSCAT_DIR = Path(f'/lustre/t0/scratch/users/luigi.silva/report_hipscat/output/hipscat/DP02_object_odd_tracts')\n",
    "MARGIN_CACHE_THRESHOLD = 1.0 #arcsec\n",
    "CATALOG_MARGIN_CACHE_NAME = \"DP02_object_odd_tracts_margin_cache\"\n",
    "###########################################################################################\n",
    "\n",
    "################################# OUTPUT CONFIGS #################################\n",
    "### Output path for the catalogs.\n",
    "OUTPUT_DIR = Path(output_dir)\n",
    "HIPSCAT_DIR_NAME = \"hipscat\"\n",
    "HIPSCAT_DIR = OUTPUT_DIR / HIPSCAT_DIR_NAME\n",
    "\n",
    "CATALOG_MARGIN_CACHE_DIR = HIPSCAT_DIR / CATALOG_MARGIN_CACHE_NAME\n",
    "\n",
    "### Path to dask performance report.\n",
    "LOGS_DIR = Path(logs_dir)\n",
    "\n",
    "PERFORMANCE_REPORT_NAME = 'performance_report_make_margin_cache_DP02_object_odd.html'\n",
    "PERFORMANCE_DIR = LOGS_DIR / PERFORMANCE_REPORT_NAME\n",
    "###########################################################################################\n",
    "\n",
    "############################### EXECUTING THE PIPELINE ######################################\n",
    "if run_the_pipeline==True:\n",
    "    with performance_report(filename=PERFORMANCE_DIR):   \n",
    "        ### Getting informations from the catalog.\n",
    "        catalog = hipscat.read_from_hipscat(CATALOG_HIPSCAT_DIR)\n",
    "\n",
    "        info_frame = catalog.partition_info.as_dataframe()\n",
    "\n",
    "        for index, partition in info_frame.iterrows():\n",
    "            file_name = result = hipscat.io.paths.pixel_catalog_file(\n",
    "                CATALOG_HIPSCAT_DIR, partition[\"Norder\"], partition[\"Npix\"]\n",
    "            )\n",
    "            info_frame.loc[index, \"size_on_disk\"] = os.path.getsize(file_name)\n",
    "\n",
    "        info_frame = info_frame.astype(int)\n",
    "        info_frame[\"gbs\"] = info_frame[\"size_on_disk\"] / (1024 * 1024 * 1024)\n",
    "        \n",
    "        ### Computing the margin cache, if it is possible.\n",
    "        number_of_pixels = len(info_frame[\"Npix\"])\n",
    "        if number_of_pixels <= 1:\n",
    "            warnings.warn(f\"Number of pixels is equal to {number_of_pixels}. Impossible to compute margin cache.\")\n",
    "        else:\n",
    "            margin_cache_args = MarginCacheArguments(\n",
    "                input_catalog_path=CATALOG_HIPSCAT_DIR,\n",
    "                output_path=HIPSCAT_DIR,\n",
    "                margin_threshold=MARGIN_CACHE_THRESHOLD,  # arcsec\n",
    "                output_artifact_name=CATALOG_MARGIN_CACHE_NAME,\n",
    "            )\n",
    "            pipeline_with_client(margin_cache_args, client)\n",
    "else:\n",
    "    print('You selected not to run the pipeline.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d472346-e031-478e-8dce-f591d254837f",
   "metadata": {},
   "source": [
    "# Doing the crossmatching between the two subsamples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d8b1e8-32d6-4f80-89b9-2c884b10b85e",
   "metadata": {},
   "source": [
    "Now, let us do the crossmatching between the two subsamples catalogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6105ad45-2819-45d6-a75e-3f9ad3e5bd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO YOU WANT TO RUN THE PIPELINE? SET FALSE IF YOU ALREADY GENERATED THE HIPSCAT CATALOG.\n",
    "run_the_pipeline = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79f0b14-339c-42b2-9671-f34f7b8d30a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## INPUT CONFIGS #################################\n",
    "LEFT_HIPSCAT_DIR = Path('/lustre/t0/scratch/users/luigi.silva/report_hipscat/output/hipscat/DP02_object_even_tracts')\n",
    "LEFT_CATALOG_HIPSCAT_NAME = 'DP02_object_even_tracts'\n",
    "RIGHT_HIPSCAT_DIR = Path('/lustre/t0/scratch/users/luigi.silva/report_hipscat/output/hipscat/DP02_object_odd_tracts')\n",
    "RIGHT_CATALOG_HIPSCAT_NAME = 'DP02_object_odd_tracts'\n",
    "RIGHT_MARGIN_CACHE_DIR = Path('/lustre/t0/scratch/users/luigi.silva/report_hipscat/output/hipscat/DP02_object_odd_tracts_margin_cache')\n",
    "\n",
    "CROSS_MATCHING_RADIUS = 1.0 # Up to 1 arcsec distance, it is the default\n",
    "NEIGHBORS_NUMBER = 1 # Single closest object, it is the default\n",
    "###########################################################################################\n",
    "\n",
    "################################# OUTPUT CONFIGS #################################\n",
    "OUTPUT_DIR = Path(output_dir)\n",
    "HIPSCAT_DIR_NAME = 'hipscat'\n",
    "HIPSCAT_DIR = OUTPUT_DIR / HIPSCAT_DIR_NAME\n",
    "\n",
    "XMATCH_NAME = LEFT_CATALOG_HIPSCAT_NAME+'_x_'+RIGHT_CATALOG_HIPSCAT_NAME\n",
    "OUTPUT_HIPSCAT_DIR = HIPSCAT_DIR / XMATCH_NAME\n",
    "\n",
    "LOGS_DIR = Path(logs_dir)\n",
    "\n",
    "PERFORMANCE_REPORT_NAME = 'performance_report_make_xmatching.html'\n",
    "PERFORMANCE_DIR = LOGS_DIR / PERFORMANCE_REPORT_NAME\n",
    "###########################################################################################\n",
    "\n",
    "############################### EXECUTING THE PIPELINE ######################################\n",
    "if run_the_pipeline==True:\n",
    "    with performance_report(filename=PERFORMANCE_DIR):\n",
    "        left_catalog = lsdb.read_hipscat(LEFT_HIPSCAT_DIR)\n",
    "        right_margin_cache_catalog = lsdb.read_hipscat(RIGHT_MARGIN_CACHE_DIR)\n",
    "        right_catalog = lsdb.read_hipscat(RIGHT_HIPSCAT_DIR, margin_cache=right_margin_cache_catalog)\n",
    "    \n",
    "        xmatched = left_catalog.crossmatch(\n",
    "            right_catalog,\n",
    "            radius_arcsec=CROSS_MATCHING_RADIUS,\n",
    "            n_neighbors=NEIGHBORS_NUMBER,\n",
    "            suffixes=(LEFT_CATALOG_HIPSCAT_NAME, RIGHT_CATALOG_HIPSCAT_NAME),\n",
    "        )\n",
    "        xmatched.to_hipscat(OUTPUT_HIPSCAT_DIR)\n",
    "else:\n",
    "    print('You selected not to run the pipeline.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c25194-8f2e-4941-a9a6-125c83726a0c",
   "metadata": {},
   "source": [
    "Reading the catalog into a dask dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9295f8-0e2c-4f1f-9936-d5c2fbd6cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DP02_xmatched_from_disk = lsdb.read_hipscat(OUTPUT_HIPSCAT_DIR)\n",
    "DP02_xmatched_from_disk_delayed = DP02_xmatched_from_disk.to_delayed()\n",
    "DP02_xmatched_from_disk_ddf = dd.from_delayed(DP02_xmatched_from_disk_delayed)\n",
    "\n",
    "print(OUTPUT_HIPSCAT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e057f13e-4356-4727-b5d3-837617d2161b",
   "metadata": {},
   "source": [
    "Plotting the first lines of the dataframe and the basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2589659c-7323-4ee9-8ec1-5949f524b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DP02_xmatched_from_disk_ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becc3879-099f-4f5b-bb3e-a9777fc7fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "DP02_xmatched_from_disk_ddf.describe().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13376e7b-a939-449f-965f-6932cb9834b5",
   "metadata": {},
   "source": [
    "# Making the scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08c84e6-547c-4e23-9330-3a176c0af59e",
   "metadata": {},
   "source": [
    "First of all, let us define the geoviews Points element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37579840-9bea-4c17-b18f-a7fdd845655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = DP02_xmatched_from_disk_ddf['coord_raDP02_object_even_tracts']\n",
    "dec = DP02_xmatched_from_disk_ddf['coord_decDP02_object_even_tracts']\n",
    "\n",
    "ra_dec_points_minusRA = gv.Points((-ra, dec), kdims=['-R.A. (deg)', 'DEC (deg)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff14613-b61a-4703-bf10-25bd472d2b37",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "In what follows, if cartopy tries to download some file from natural earth, check the path of the cartopy data directory with\n",
    "```python\n",
    "import cartopy\n",
    "print(cartopy.config['data_dir'])\n",
    "```\n",
    "Then, download the file manually to the ```shapefiles/natural_earth/physical``` folder inside this directory and unzip it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a67794d-381b-49ef-bdc8-461f8e8626d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot using the Plate Carrée projection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b33ee9f-0a70-485d-afb0-9447c2bcfca7",
   "metadata": {},
   "source": [
    "Defining the title, the axis labels and the plot sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57d2dcd-dbc1-4b68-954d-b0b087c76b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Spatial distribution - X-matched objects of even and odd tracts - Plate Carrée projection'\n",
    "height = 500\n",
    "width = 1000\n",
    "padding = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae158df-efa1-4eab-aa5f-78ae96d3849e",
   "metadata": {},
   "source": [
    "Making the plot with geoviews and datashader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc38f2e3-9b23-4462-9d1a-b8e9cab1a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "Plate_Carree_rasterized_points = rasterize(ra_dec_points_minusRA, aggregator=ds.count()).opts(cmap=\"Viridis\", cnorm='log')\n",
    "\n",
    "Plate_Carree_spread_points = dynspread(Plate_Carree_rasterized_points).opts(width=width, height=height, padding=padding, title=title, toolbar='above', colorbar=True, \n",
    "                                                                            tools=['box_select'], show_grid=True)\n",
    "\n",
    "Plate_Carree_spread_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43307deb-445b-4cd1-b6d5-06cb8961634e",
   "metadata": {},
   "source": [
    "### Plot using the Mollweide projection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7e244e-8cac-4fdd-9408-4d125b381e66",
   "metadata": {},
   "source": [
    "Defining the title, the axis labels and the plot sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9a3f42-b50b-443f-8e13-1584cc877056",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Spatial distribution - X-matched objects of even and odd tracts - Mollweide projection'\n",
    "height = 500\n",
    "width = 1000\n",
    "padding = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d59aa9-a579-4c14-bd01-c189e6bcef81",
   "metadata": {},
   "source": [
    "Defining the RA and DEC ticks for the Mollweide projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ace09d1-c3ad-4ef9-87f9-554160e46b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "longitudes = np.arange(30, 360, 30)\n",
    "latitudes = np.arange(-75, 76, 15)\n",
    "\n",
    "lon_labels = [f\"{lon}°\" for lon in longitudes]\n",
    "lat_labels = [f\"{lat}°\" for lat in latitudes]\n",
    "\n",
    "labels_data = {\n",
    "    \"lon\": list(np.flip(longitudes)) + [-180] * len(latitudes),\n",
    "    \"lat\": [0] * len(longitudes) + list(latitudes),\n",
    "    \"label\": lon_labels + lat_labels,\n",
    "}\n",
    "\n",
    "df_labels = pd.DataFrame(labels_data)\n",
    "\n",
    "labels_plot = gv.Labels(df_labels, kdims=[\"lon\", \"lat\"], vdims=[\"label\"]).opts(\n",
    "    text_font_size=\"12pt\",\n",
    "    text_color=\"black\",\n",
    "    text_align='right',\n",
    "    text_baseline='bottom',\n",
    "    projection=crs.Mollweide()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759500c7-2c0f-47a6-a9bd-4ce5de95d779",
   "metadata": {},
   "source": [
    "Making the plot with geoviews and datashader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de426c6d-8bdf-4529-98d3-135e1505bbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "projected = gv.operation.project(ra_dec_points_minusRA, projection=crs.Mollweide())\n",
    "\n",
    "Mollweide_rasterized_points = rasterize(projected, aggregator=ds.count()).opts(cmap=\"Viridis\", cnorm='log')\n",
    "\n",
    "Mollweide_spread_points = dynspread(Mollweide_rasterized_points).opts(width=width, height=height, padding=padding, title=title, toolbar='above', colorbar=True, \n",
    "                                                                            tools=['box_select'])\n",
    "\n",
    "grid = gf.grid()\n",
    "\n",
    "Mollweide_spread_points * grid * labels_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0723fd4c-9757-48e2-8846-758a0b1aaf55",
   "metadata": {},
   "source": [
    "# Printing and saving just the objectIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10977f41-233b-4bb5-94e3-d68df167e7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ids = DP02_xmatched_from_disk[['objectIdDP02_object_even_tracts', 'objectIdDP02_object_odd_tracts']].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9667cac7-b47d-49ce-b090-f53baafd0c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_to_save = 30\n",
    "df_ids.head(number_to_save).to_csv(f'duplicates_even_tracts_vs_odd_tracts_sample_of_{number_to_save}_objects.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105c6d71-356b-430b-8362-6f8f8841a72e",
   "metadata": {},
   "source": [
    "# Closing the client and cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cc4f7b-bcd9-40f5-b6fc-2d9f71a24a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fechando o client\n",
    "client.close()\n",
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ondemand-kernel",
   "language": "python",
   "name": "ondemand-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

#!/usr/bin/env python3
#SBATCH --spread-job
#SBATCH --time=2:00:00
#SBATCH -p sequana_cpu
#SBATCH -J rail-slurm
#SBATCH --mem-per-cpu=2G
#SBATCH -N 10-50
#SBATCH --ntasks-per-node=48
#SBATCH --exclude=sdumont5041

# This script calls rail-estimate on the cluster.
#
# Usage:
#
#     $ sbatch [<sbatch_options>...] rail-slurm.batch \
#             [<input_dir> [<output_dir> [<algorithm>]]]
#
# - input_dir: Input directory with pre-processed input data
# - output_dir: Target output directory for the estimations
# - algorithm: The estimation algorithm (fzboost or BPZ)
#
# The rail-estimate program also requires an estimator_<algorithm>.pkl
# file available in the current directory or in a standard data directory.
# In case of BPZ algorithm, the BPZ cache files (AB directory) must have
# been previously generated.
#
# Example usage:
#
#     # Defaults: input_dir=input, output_dir=output, algorithm=fzboost
#     $ sbatch rail_slurm.batch
#
#     # Change the slurm queue
#     $ sbatch -p cpu_long -t 8:00:00 -N20 --ntasks-per-node=40 \
#             input1 output1 bpz
#
# This script is somewhat "Unix intensive" because it tries to exploit support
# for dynamic scheduling on slurm. It calls "srun" in parallel and keeps calling
# it while previous "srun" executions finish, keeping the cluster's task slots
# fully allocated until all files are processed.

from contextlib import contextmanager
from datetime import datetime
from glob import glob
from os import P_NOWAIT, WNOHANG, chdir, environ, getcwd, kill, makedirs, \
        spawnv, waitpid
from os.path import dirname, getsize, isfile, join, relpath
from shutil import which
from signal import SIGHUP
from sys import argv, stderr
from time import sleep

SRUN = 'srun'
SRUN_ARGS = [SRUN, '-n1', '-N1', '--exact']
LOG = 'log'
PROG = 'rail-slurm'
ESTIMATE = 'rail-estimate'
ESTIMATE_ARGS = ['--bins=301']
OUTPUT_DIR = 'output'
INPUT_DIR = 'input'
ALGORITHM = 'fzboost'

# Spawns a single task to a single cluster slot
def srun(cmd, stdout, stderr):
    args = SRUN_ARGS + ['--output', stdout, '--error', stderr] + list(cmd)

    return spawnv(P_NOWAIT, SRUN_PATH, args)

def stdout_name(task_id):
    return join(LOG, '%s-%d.out' % (PROG, task_id))

def stderr_name(task_id):
    return join(LOG, '%s-%d.err' % (PROG, task_id))

# Best effort cleanup on abnormal program termination
def try_kill_children(children):
    for pid in children:
        kill(pid, SIGHUP)

    sleep(1)

    for _ in children:
        waitpid(-1, WNOHANG)

def info(msg):
    print(msg, file=stderr, flush=True)

@contextmanager
def now(msg):
    info('%s: Starting: %s' % (datetime.now(), msg))
    yield
    info('%s: Finished: %s' % (datetime.now(), msg))

def parallel(files, slots, input_dir, output_base_dir, algorithm):
    children = {}
    task_id = 0

    while len(children) > 0 or len(files) > 0:
        # Keep all cluster slots full by spawning each task
        while len(children) < slots and len(files) > 0:
            relative_path = files.pop()
            input_file = join(input_dir, relative_path)
            output_file = join(output_base_dir, relative_path)
            output_dir = dirname(output_file)
            stdout_file = stdout_name(task_id)
            stderr_file = stderr_name(task_id)
            args = [ESTIMATE_PATH] + ESTIMATE_ARGS + ['-a', algorithm] + \
                    [input_file, output_file]

            makedirs(output_dir, exist_ok=True)

            info('%s: Starting: %s %s id=%d' % (datetime.now(), ESTIMATE,
                relative_path, task_id))

            pid = srun(args, stdout_file, stderr_file)
            children[pid] = (relative_path, task_id)
            task_id += 1

        # Wait for tasks to finish
        if len(children) > 0:
            pid, ret = waitpid(-1, 0)
            prev_relative_path, prev_task_id = children.pop(pid)

            if ret != 0:
                try_kill_children(children)
                raise RuntimeError('Error: child process returned failure (%d).'
                        % ret)

            info('%s: Finished: %s %s id=%d' % (datetime.now(), ESTIMATE,
                prev_relative_path, prev_task_id))

            # Best effort delay to avoid srun's "node is busy" messages, give a
            # little breathing room to the nodes.
            sleep(0.005)

def get_input_files(input_dir):
    cwd = getcwd()
    chdir(input_dir)
    try:
        return [path for path in glob('**/*', recursive=True) if isfile(path)]
    finally:
        chdir(cwd)

def parse_cmdline():
    if len(argv) > 1:
        input_dir = argv[1]
    else:
        input_dir = INPUT_DIR

    if len(argv) > 2:
        output_dir = argv[2]
    else:
        output_dir = OUTPUT_DIR

    if len(argv) > 3:
        algorithm = argv[3]
    else:
        algorithm = ALGORITHM

    return input_dir, output_dir, algorithm

def find_program_paths():
    with now('finding program paths'):
        srun = which(SRUN)
        if not srun:
            raise RuntimeError('Unable to find %s program.' % SRUN)
        info(srun)
        estimate = which(ESTIMATE)
        if not estimate:
            raise RuntimeError('Unable to find %s program.' % ESTIMATE)
        info(estimate)

        global SRUN_PATH, ESTIMATE_PATH

        SRUN_PATH = srun
        ESTIMATE_PATH = estimate


def main():
    with now(PROG):
        slots = int(environ['SLURM_NTASKS'])
        input_dir, output_dir, algorithm = parse_cmdline()
        files = get_input_files(input_dir)
        find_program_paths()
        parallel(files, slots, input_dir, output_dir, algorithm)

if __name__ == '__main__': main()

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c39e9a-a601-40d5-b77e-dff606ca8571",
   "metadata": {},
   "source": [
    "<img align='left' src = '../images/linea.png' width=150 style='padding: 20px'> \n",
    "\n",
    "# PZ Compute - Input Data QA Notebook - DP0.2\n",
    "\n",
    "Collection of objects made available by Rubin Observatory Legacy Survey of Space and Time (LSST), release Data Preview 0.2 (DP0.2).\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6939f3b-1a2b-4c83-8304-7fb8b4979b58",
   "metadata": {},
   "source": [
    "Contact: Luigi Silva ([luigi.lcsilva@linea.org.br](mailto:luigi.lcsilva@linea.org.br))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9dd449-c148-4cf8-bce6-b6ffc058a1d8",
   "metadata": {},
   "source": [
    "Last check: September 2, 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc7460e-d0ab-4147-9b88-bf2778b8bd41",
   "metadata": {},
   "source": [
    "#### Acknowledgements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a50fcb-36ef-4d8f-88a2-ff03d1e1c27e",
   "metadata": {},
   "source": [
    "'_This notebook used computational resources from the Associação Laboratório Interinstitucional de e-Astronomia (LIneA) with the financial support of INCT do e-Universo (Process no. 465376/2014-2)._'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdc0e56-3f9f-463d-a034-d5818cc20e46",
   "metadata": {},
   "source": [
    "#### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e3e0f2-158a-4917-bd63-a7cfca93bec4",
   "metadata": {},
   "source": [
    "Before running the notebook, check the instructions in the ```pz-compute/doc/notebooks/DP02_QA_notebook_input.md``` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c5fa6e-892d-4665-b449-b3e96c6c6fa8",
   "metadata": {},
   "source": [
    "# About the survey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a4a026-6080-4f8e-9df4-6df2cc125b56",
   "metadata": {},
   "source": [
    "The data set used for DP0.2 is the $300 \\text{ deg}^2$ of simulated, LSST-like images and catalogs generated by the Dark Energy Science Collaboration (DESC) for their Data Challenge 2 (DC2) ([DP0.2 Docs](https://dp0-2.lsst.io/))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6305a0c7-5879-434f-adf4-a3c113564815",
   "metadata": {},
   "source": [
    "|seq.|Survey name <br> (link to the website)| Number of objects in <br>the original sample | Reference <br> (link to the paper) |\n",
    "|---|---|:-:|---|\n",
    "|1|[DP0.2](https://dp0-2.lsst.io/)|~200 million astronomical objects|[LSST Dark Energy Science Collaboration (LSST DESC)](https://ui.adsabs.harvard.edu/abs/2021ApJS..253...31L/abstract)| "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15938488-3719-489e-97eb-f8b10fed3820",
   "metadata": {},
   "source": [
    "The complete table schema for DP0.2 can be found [here](https://dm.lsst.org/sdm_schemas/browser/dp02.html). In this noteboook, we will use the skinny tables generated using the LIneA Apollo Cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e6b320-c1c8-4545-ba8d-fbd9a1b5bbe8",
   "metadata": {},
   "source": [
    "The skinny tables have the following columns: coord_ra; coord_dec; mag_u; mag_g; mag_r; mag_i; mag_z; mag_y; magerr_u; magerr_g; magerr_r; magerr_i; magerr_z; magerr_y; objectId. These columns correspond to the R.A. and DEC coordinates, the magnitudes measurements and the magnitudes errors for each band, and the objects unique identifiers, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12661c77-71fa-468d-8656-e4a8f192b2cd",
   "metadata": {},
   "source": [
    "# Inputs and configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9c079f-4eb7-4537-9aa5-d064f7fc1d08",
   "metadata": {},
   "source": [
    "Requirements for this notebook:\n",
    "\n",
    "* **General libraries**: os, sys, math, numpy, pandas.\n",
    "* **Visualization libraries**: bokeh, holoviews, geoviews, cartopy.\n",
    "\n",
    "It is also necessary to install the **fastparquet** library for reading the parquet files with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819054eb-dfb2-4d11-94bf-0a46b8e9f4c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Bokeh\n",
    "import bokeh\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "# Holoviews\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "\n",
    "# Geoviews\n",
    "import geoviews as gv\n",
    "import geoviews.feature as gf\n",
    "from geoviews.operation import project\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5195c7c-4456-4018-be1f-999b1fea9e24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06797a9d-aac7-4577-8239-1d96cdcf4a65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a1b862-091d-4048-8c26-a7915dcf4ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e25646-e514-43c5-8f5e-1d8ea30a0cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc6bc75-d2e7-46bc-a120-65bfc9c3d2b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd33028-2a4f-4c26-83b5-23f386222da2",
   "metadata": {},
   "source": [
    "# Basic Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99176c53-41a8-40ad-ac7e-4561bc5a7d38",
   "metadata": {},
   "source": [
    "In this section, we will show the basic statistics of the data. In both tables, we will find, for each column, the count number of non-NA/null observations, the maximum value, minimum value, mean, standard deviation and the 25th, 50th and 75th percentiles.\n",
    "\n",
    "The first table was obtained by applying the method ```describe```, from the pandas library, in the entire input dataset, without any filtering.\n",
    "\n",
    "The second table was obtained by applying the same method, but this time filtering all the NaN and inf values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba2be26-e880-416a-bf4b-c51d15f0ab31",
   "metadata": {},
   "source": [
    "### How to get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffdeb69-2959-4801-8946-0d3b88994677",
   "metadata": {},
   "source": [
    "The files containing the data of the basic statistics were obtained using High Performance Computing (HPC) in the LIneA Apollo Cluster. There is a Python script that reads all the input Parquet files and computes the basic statistics. There is also an sbatch file used to submit the job to the cluster. They can be found in ```pz-compute/doc/dp02_qa_scripts/```.\n",
    "\n",
    "Files:\n",
    "1. Detailed instructions to run the scripts: ```DP02_QA_slurm_scripts_instructions.md```\n",
    "1. Python script: ```DP02_QA_basic_stats.py```\n",
    "2. Sbatch script: ```DP02_QA_basic_stats.sbatch```\n",
    "3. Resulting Parquet files containing the data: ```basic_stats.parquet``` and ```basic_stats_no_nan_no_inf.parquet```\n",
    "\n",
    "For running the .py script in the cluster, you must follow the steps in the corresponding ```.md``` file.\n",
    "\n",
    "For this Jupyter notebook, the output files ```basic_stats.parquet``` and ```basic_stats_no_nan_no_inf.parquet``` must be in the ```output``` folder, and this ```output``` folder must be in the same directory of the notebook itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b795fc40-4d59-47b5-840e-1d74691bd78a",
   "metadata": {},
   "source": [
    "## Showing the basic statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2edb032-6a3c-495c-a71d-9b1cff87d702",
   "metadata": {},
   "source": [
    "Below, we can see the first table, containing the basic statistics for the entire input dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a17b23-e601-43eb-965c-be9a418acc01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Reading the Parquet file and showing the dataframe.\n",
    "df_basic_stats = pd.read_parquet('output/basic_stats.parquet', engine='fastparquet')\n",
    "df_basic_stats "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ec6784-fc14-4a3e-932e-82f4da32a1ad",
   "metadata": {},
   "source": [
    "The second table is shown below, containing the basic statistics ignoring all NaN and inf values in all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176dc419-c5e8-4591-bd88-6c83879e3bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Reading the Parquet file and showing the dataframe.\n",
    "df_basic_stats_no_nan_no_inf = pd.read_parquet('output/basic_stats_no_nan_no_inf.parquet', engine='fastparquet')\n",
    "df_basic_stats_no_nan_no_inf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfb1d8e-fb4c-4b61-ba28-729f50ea753b",
   "metadata": {},
   "source": [
    "# Spatial distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d98a2cf-9ffc-4cf2-879f-9dce0ea57bf3",
   "metadata": {},
   "source": [
    "In the following subsections, we will read the data of the 2D histogram corresponding to the **spatial distribution of objects**, considering their distribution in the sky according to their Right Ascension (R.A.) and Declination (DEC) coordinates, and we will make two plots.\n",
    "\n",
    "The first plot uses the **equidistant cylindrical projection (Plate Carrée projection)**, in which the lines corresponding to R.A. are equally spaced vertical straight lines, and the lines corresponding to DEC are equally spaced horizontal straight lines. This projection distorts areas and shapes, especially at high declinations.\n",
    "\n",
    "The second plot uses the **Mollweide projection**, an equal-area, pseudocylindrical map projection. The Mollweide projection preserves area; however, it distorts shapes, especially near the edges of the sky map. The central meridian and the celestial equator are straight lines, while other lines of R.A. and DEC are represented as curves.\n",
    "\n",
    "Both graphs will also have a **colorbar** corresponding to the counts of objects per R.A. and DEC bin of the 2D histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4515cb4d-0a45-483e-b565-f3be665fdad3",
   "metadata": {},
   "source": [
    "### How to get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee76dcf-44c6-43b6-b04c-d4db8e01725f",
   "metadata": {},
   "source": [
    "The file containing the data of the 2D histogram was obtained using High Performance Computing (HPC) in the LIneA Apollo Cluster. There is a Python script that reads all the input Parquet files and computes the 2D histogram. In this Python file, you can personalize the R.A. and DEC bin edges. There is also an sbatch file used to submit the job to the cluster. They can be found in ```pz-compute/doc/dp02_qa_scripts/```.\n",
    "\n",
    "Files:\n",
    "1. Detailed instructions to run the scripts: ```DP02_QA_slurm_scripts_instructions.md```\n",
    "1. Python script: ```DP02_QA_histo_2d_ra_dec.py```\n",
    "2. Sbatch script: ```DP02_QA_histo_2d_ra_dec.sbatch```\n",
    "3. Resulting Parquet file containing the data: ```histo_2d_ra_dec.parquet```\n",
    "\n",
    "For running the .py script in the cluster, you must follow the steps in the corresponding ```.md``` file.\n",
    "\n",
    "For this Jupyter notebook, the output file ```histo_2d_ra_dec.parquet``` must be in the ```output``` folder, and this ```output``` folder must be in the same directory of the notebook itself.\n",
    "\n",
    "**For the spatial distribution of objects, we do not compute one 2D histogram for each input Parquet file, just the total histogram considering all files together.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85420921-b3dd-4e29-873e-6d335f8f245c",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c313412f-e844-42c6-a26f-5d1a6351a2b7",
   "metadata": {},
   "source": [
    "Below we can see the output Parquet file structure. The line 0 (type \"histogram_ra_dec\") contains the counts of the 2D histogram in the \"values\" column, and the line 1 (type \"bins_ra_dec\") contains the R.A. bin edges (\"ra_bins\") and DEC bin edges (\"dec_bins\") in the \"values\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae27ee57-5596-420f-ba89-69987deb1222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Reading the Parquet file and showing the dataframe.\n",
    "df_spatial_dist = pd.read_parquet('output/histo_2d_ra_dec.parquet', engine='fastparquet')\n",
    "df_spatial_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caded6b2-8827-47b3-9a97-3131d7df06e8",
   "metadata": {},
   "source": [
    "We have to convert the lists to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69407cd-781c-40d4-ae0d-4271ab665fb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Generating new dataframes from the original one, containing the counts, the R.A. bin edges and the DEC bin edges, and converting\n",
    "### these dataframes to numpy arrays.\n",
    "histogram_ra_dec = np.array(df_spatial_dist['values'][0])\n",
    "bins_ra = np.array(df_spatial_dist['values'][1]['ra_bins'])\n",
    "bins_dec = np.array(df_spatial_dist['values'][1]['dec_bins'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8909e2f-c6da-49f4-b3d7-d7eaeee929d8",
   "metadata": {},
   "source": [
    "Now, we show some information about the R.A. bins, DEC bins and the 2D histogram counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02314396-2a91-46db-90b6-572204dd215a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Printing the information.\n",
    "print(\"INFO - R.A. BINS\")\n",
    "print(f\"Min. edge: {bins_ra.min():.2f} | Max. edge: {bins_ra.max():.2f} | Step: {bins_ra[1]-bins_ra[0]:.2f} | Shape: {bins_ra.shape} \\n\")\n",
    "print(\"INFO - DEC BINS\")\n",
    "print(f\"Min. edge: {bins_dec.min():.2f} | Max. edge: {bins_dec.max():.2f} | Step: {bins_dec[1]-bins_dec[0]:.2f} | Shape: {bins_dec.shape} \\n\") \n",
    "print(\"INFO- 2D HISTOGRAM COUNTS\")\n",
    "print(f\"Min. count: {histogram_ra_dec.min()} | Max. count: {histogram_ra_dec.max()} | Shape: {histogram_ra_dec.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77e74de-145e-4967-8af5-e96cf2af593f",
   "metadata": {},
   "source": [
    "## Spatial distribution plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2c3788-0426-4cdd-a9a6-2ca0b12e6b85",
   "metadata": {},
   "source": [
    "Before making the plots, we must perform some tasks:\n",
    "\n",
    "1. Change the 0 values in the 2D histogram counts array to NaN values, so that they appear white in the plot.\n",
    "2. Compute the centers of the bins.\n",
    "3. For the Plate Carrée projection, change the R.A. coordinates so that they belong to the range $[−180^{\\circ},180^{\\circ})$. This is necessary for inverting the x-axis in the plot, a widely used convention. We must also adjust the 2D histogram counts accordingly, so that they agree with the new R.A. range.\n",
    "4. For the Mollweide projection, invert the R.A. coordinates by doing $360^{\\circ} - x$ for all $x$ in the R.A. values. This is just computational artifice, which is necessary for inverting the x-axis in the plot. However, in the final plot, the R.A. and DEC ticks will be correctly showed in the original range, $[0^{\\circ},360^{\\circ})$. Again, we must also adjust the 2D histogram counts accordingly.\n",
    "5. Transpose the 2D histogram counts arrays so that they become compatible with HoloViews/GeoViews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59c755e-b571-4648-8643-931bd7ca9307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Changing the 0 values to NaN values.\n",
    "histogram_ra_dec_NaN = histogram_ra_dec.astype(float)\n",
    "histogram_ra_dec_NaN[histogram_ra_dec_NaN == 0] = np.nan\n",
    "\n",
    "### Getting the bins centers.\n",
    "bins_ra_centers = (bins_ra[1:] + bins_ra[:-1])/2\n",
    "bins_dec_centers = (bins_dec[1:] + bins_dec[:-1])/2\n",
    "\n",
    "### Plate Carrée projection - Changing the R.A. coordinates to the range [-180,180), and changing the 2d histogram counts accordingly.\n",
    "bins_ra_centers_180_range = np.where(bins_ra_centers >= 180, bins_ra_centers - 360, bins_ra_centers)\n",
    "sorted_indices_180_range = np.argsort(bins_ra_centers_180_range)\n",
    "histogram_ra_dec_180_range = histogram_ra_dec_NaN[sorted_indices_180_range, :]\n",
    "bins_ra_centers_180_range = bins_ra_centers_180_range[sorted_indices_180_range]\n",
    "\n",
    "### Mollweide projection - Inverting the R.A. values (360 - values), and changing the 2d histogram counts accordingly.\n",
    "bins_ra_centers_inverted = np.where(bins_ra_centers <= 360, 360 - bins_ra_centers, bins_ra_centers)\n",
    "sorted_indices_inverted = np.argsort(bins_ra_centers_inverted)\n",
    "histogram_ra_dec_inverted = histogram_ra_dec_NaN[sorted_indices_inverted, :]\n",
    "bins_ra_centers_inverted = bins_ra_centers_inverted[sorted_indices_inverted]\n",
    "\n",
    "### Transposing the histogram arrays for the holoviews plots.\n",
    "histogram_ra_dec_180_range_transpose = histogram_ra_dec_180_range.T\n",
    "histogram_ra_dec_inverted_transpose = histogram_ra_dec_inverted.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f4cfb6-fe97-4dd3-8aa1-7014fd57adbf",
   "metadata": {},
   "source": [
    "After these tasks, we are ready to make the spatial distribution plots.\n",
    "\n",
    "First, the Plate Carrée projection plot. In this plot, **the R.A. values are in the $[−180^{\\circ},180^{\\circ})$ range**, where the negative values corresponds to values greater than $180^{\\circ}$ in the original range, $[0^{\\circ}, 360^{\\circ})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80af0fc8-f317-4fc0-a709-bfc07f40b9eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Creating the image using holoviews.\n",
    "hv_image_ra_dec = hv.Image((bins_ra_centers_180_range, bins_dec_centers, histogram_ra_dec_180_range_transpose), [f'R.A.', f'DEC'], f'Counts')\n",
    "\n",
    "### Adjusting the image options.\n",
    "hv_image_ra_dec = hv_image_ra_dec.opts(\n",
    "    opts.Image(cmap='viridis', cnorm='linear', colorbar=True, width=1000, height=500,\n",
    "               xlim=(180, -180), ylim=(-90, 90), tools=['hover'], clim=(10, np.nanmax(histogram_ra_dec_180_range_transpose)),\n",
    "               title=f'Spatial Distribution of Objects - Plate Carrée projection', show_grid=True)\n",
    ")\n",
    "\n",
    "# Showing the graph.\n",
    "hv_image_ra_dec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30414ebc-8ad7-45ad-8a40-881bb4577138",
   "metadata": {},
   "source": [
    "Second, the Mollweide projection plot. In this plot, **the R.A. values are in the original $[0^{\\circ},360^{\\circ})$ range**. Unfortunately, the bokeh 'hover' tool does not work with this projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09247c5d-5757-4117-964e-a81d036af7fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Generating the R.A. and DEC ticks\n",
    "longitudes = np.arange(30, 360, 30)\n",
    "latitudes = np.arange(-75, 76, 15)\n",
    "\n",
    "lon_labels = [f\"{lon}°\" for lon in longitudes]\n",
    "lat_labels = [f\"{lat}°\" for lat in latitudes]\n",
    "\n",
    "labels_data = {\n",
    "    \"lon\": list(np.flip(longitudes)) + [-180] * len(latitudes),\n",
    "    \"lat\": [0] * len(longitudes) + list(latitudes),\n",
    "    \"label\": lon_labels + lat_labels,\n",
    "}\n",
    "\n",
    "df_labels = pd.DataFrame(labels_data)\n",
    "\n",
    "labels_plot = gv.Labels(df_labels, kdims=[\"lon\", \"lat\"], vdims=[\"label\"]).opts(\n",
    "    text_font_size=\"12pt\",\n",
    "    text_color=\"black\",\n",
    "    text_align='right',\n",
    "    text_baseline='bottom',\n",
    "    projection=ccrs.Mollweide()\n",
    ")\n",
    "\n",
    "### Creating the image using holoviews.\n",
    "gv_image_ra_dec = gv.Image((bins_ra_centers_inverted, bins_dec_centers, histogram_ra_dec_inverted_transpose), [f'R.A.', f'DEC'], f'Counts')\n",
    "\n",
    "### Doing the Mollweide projection.\n",
    "gv_image_ra_dec_projected = gv.operation.project(gv_image_ra_dec, projection=ccrs.Mollweide())\n",
    "\n",
    "### Generating the grid lines.\n",
    "grid = gf.grid().opts(\n",
    "    opts.Feature(projection=ccrs.Mollweide(), scale='110m', color='black')\n",
    ")\n",
    "\n",
    "### Adjusting the image options.\n",
    "gv_image_ra_dec_projected = gv_image_ra_dec_projected.opts(cmap='viridis', cnorm='linear', colorbar=True, width=1000, height=500, \n",
    "                                                           clim=(10, np.nanmax(histogram_ra_dec_inverted_transpose)), \n",
    "                                                           title='Spatial Distribution of Objects - Mollweide projection', \n",
    "                                                           projection=ccrs.Mollweide(),  global_extent=True)\n",
    "\n",
    "### Showing the plot.\n",
    "combined_plot = gv_image_ra_dec_projected * grid * labels_plot\n",
    "combined_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f29de4-d106-44de-a77c-21c973eb4715",
   "metadata": {},
   "source": [
    "# Magnitude distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8399146d-640e-4ab7-bc4d-ac9386ba5226",
   "metadata": {},
   "source": [
    "In the following subsections, we will read the data of the 1D histograms corresponding to the **magnitude distributions** and we will make plots for each band of the survey."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e22bd2-3997-4329-8cfb-ac68884d2eb8",
   "metadata": {},
   "source": [
    "### How to get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44931e47-21ca-43fc-ade7-26562b384a47",
   "metadata": {},
   "source": [
    "The file containing the data of the 1D histogram was obtained using High Performance Computing (HPC) in the LIneA Apollo Cluster. There is a Python script that reads all the input Parquet files and computes the 1D histogram. In this Python file, you can personalize the magnitude bin edges for each band. There is also a sbatch file used to submit the job to the cluster. They can be found in ```pz-compute/doc/dp02_qa_scripts/```.\n",
    "\n",
    "Files:\n",
    "1. Detailed instructions to run the scripts: ```DP02_QA_slurm_scripts_instructions.md```\n",
    "1. Python script: ```DP02_QA_histo_1d_mag.py```\n",
    "2. Sbatch script: ```DP02_QA_histo_1d_mag.sbatch```\n",
    "3. Resulting Parquet file containing the data: ```histo_1d_mag_all_bands.parquet```\n",
    "\n",
    "For running the .py script in the cluster, you must follow the steps in the corresponding ```.md``` file.\n",
    "\n",
    "For this Jupyter notebook, the output file ```histo_1d_mag_all_bands.parquet``` must be in the ```output``` folder, and this ```output``` folder must be in the same directory of the notebook itself.\n",
    "\n",
    "**For the magnitude distributions, we compute one 1D histogram for each input Parquet file, for each band. Given a certain band, we use the same bin edges for each input file.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6ce14d-6dc8-4545-8b06-e9765517cf51",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10061e87-0a6d-4841-9b71-6fe68ab4d85d",
   "metadata": {},
   "source": [
    "Below we can see the Parquet file structure. When the value of the 'filename' column is a path, the values of the 'counts' column are the 1D histogram counts for the file corresponding to this path. When the value of the 'filename' column is 'bins', the values of the 'counts' column are the bin edges used for each band.\n",
    "\n",
    "We also split, in the code lines, the original dataframe (df_mag) into a list of dataframes containing only the 2D histograms counts (mag_histograms), for each band, and a dataframe containing only the bins (mag_bins), and we convert the values to numpy.arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c7f48a-d858-4554-9b56-49939635233e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Reading the Parquet file.\n",
    "df_mag = pd.read_parquet('output/histo_1d_mag_all_bands.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e83da6-80ca-4bf3-a2a0-17d2b8b4f88d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Getting the bands names and the number of bands.\n",
    "bands_mag = df_mag['band'].unique()\n",
    "num_of_bands_mag = len(bands_mag)\n",
    "\n",
    "### Separating the histograms of each band and the bin edges, and converting the lists to numpy arrays.\n",
    "mag_histograms = {}\n",
    "for band in bands_mag:\n",
    "    mag_histograms[band] = df_mag[df_mag['band'] == band]\n",
    "    mag_histograms[band] = mag_histograms[band][mag_histograms[band]['filename'] != 'bins']\n",
    "    mag_histograms[band] = mag_histograms[band].reset_index(drop=True)\n",
    "    mag_histograms[band]['counts'] = mag_histograms[band]['counts'].apply(np.array)\n",
    "\n",
    "mag_bins = df_mag[df_mag['filename'] == 'bins']\n",
    "mag_bins = mag_bins.reset_index(drop=True)\n",
    "mag_bins['counts'] = mag_bins['counts'].apply(np.array)\n",
    "\n",
    "### Getting the input files names and the number of input files.\n",
    "filenames_paths_mag = df_mag['filename'].unique()\n",
    "filenames_paths_mag = filenames_paths_mag[filenames_paths_mag!='bins']\n",
    "filenames_paths_mag = filenames_paths_mag.astype(str)\n",
    "filenames_mag = np.char.replace(filenames_paths_mag, '/lustre/t1/cl/lsst/dp02/secondary/catalogs/skinny/hdf5/', '')\n",
    "filenames_len_mag = len(filenames_mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e53b1d-a7f9-495e-b4c1-a157a6318da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### PRINTING THE INFORMATION\n",
    "### GENERAL INFORMATION\n",
    "print(f\"MAG. DIST. - NUMBER OF BANDS: {num_of_bands_mag}\")\n",
    "print(f\"MAG. DIST. - BAND NAMES: {bands_mag}\")\n",
    "print(f\"MAG. DIST. - NUMBER OF INPUT FILES: {filenames_len_mag}\")\n",
    "print(f\"EACH BAND HAS A TOTAL OF {filenames_len_mag} LINES, CORRESPONDING TO EACH INPUT FILE, PLUS ONE EXTRA LINE, CORRESPONDING TO THE BIN EDGES.\\n\")\n",
    "\n",
    "### INDIVIDUAL HISTOGRAMS PREVIEW\n",
    "printing_lines_for_each_band = 2\n",
    "print(f\"\\nPRINTING {printing_lines_for_each_band} LINES FOR EACH BAND, CONTAINING THE 1D HISTOGRAM COUNTS.\")\n",
    "for band in bands_mag:\n",
    "    print(mag_histograms[band].head(printing_lines_for_each_band))\n",
    "    print('\\n')\n",
    "\n",
    "### BIN EDGES PREVIEW\n",
    "print(f\"\\nPRINTING THE LINES CONTAINING THE BIN EDGES (THEY CAN BE FOUND AT THE END OF THE PARQUET FILE)\")\n",
    "print(mag_bins.head())\n",
    "\n",
    "### BIN EDGES INFORMATION\n",
    "print(\"\\n\\nINFORMATION ABOUT THE BINS\")\n",
    "for band in bands_mag:\n",
    "    bin_list = mag_bins[mag_bins['band']==band]['counts'].reset_index(drop=True)[0]\n",
    "    bin_min = bin_list.min()\n",
    "    bin_max = bin_list.max()\n",
    "    step = bin_list[1] - bin_list[0]\n",
    "    shape = bin_list.shape\n",
    "    print(f\"Min. bin edge - band {band}: {bin_min}\")\n",
    "    print(f\"Max. bin edge - band {band}: {bin_max}\")\n",
    "    print(f\"Step - band {band}: {step}\")\n",
    "    print(f\"Shape - band {band}: {shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc25ec1-154d-4745-b84b-59dd44d0f2a6",
   "metadata": {},
   "source": [
    "Now, we will compute the total 1D histogram for each band. This is done by summing the values in each bin for all the individual histograms. Below, we show some information about the total 1D histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c57b280-11a1-45c1-9101-f4dc25794514",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Computing the total 1D histogram.\n",
    "total_mag_histograms = {}\n",
    "for band in bands_mag:\n",
    "    arrays = {}\n",
    "    num_of_rows = len(mag_histograms[band].index)\n",
    "    for j in np.arange(0, num_of_rows, 1):\n",
    "        name = 'array'+str(j)\n",
    "        arrays[name] = mag_histograms[band]['counts'][j]\n",
    "\n",
    "    somas = []\n",
    "\n",
    "    for elementos in zip(*arrays.values()):\n",
    "        soma = sum(elementos) \n",
    "        somas.append(soma)\n",
    "\n",
    "    data = {'counts': somas,\n",
    "            'bin_edges': mag_bins.loc[mag_bins['band'] == band, 'counts'].values[0][:-1]}\n",
    "\n",
    "    total_mag_histograms[band] = pd.DataFrame(data)\n",
    "    \n",
    "### Printing the information.\n",
    "print(\"INFORMATION ABOUT THE TOTAL 1D HISTOGRAM COUNTS\")\n",
    "for band in bands_mag:\n",
    "    print(f\"Min. count - band {band}: {total_mag_histograms[band]['counts'].min()}\")\n",
    "    print(f\"Max. count - band {band}: {total_mag_histograms[band]['counts'].max()}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c341446-8926-4a22-9581-8b1f48fc8444",
   "metadata": {},
   "source": [
    "## Magnitude distributions plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63acbd3-7994-4b98-a989-c2ac180c5d19",
   "metadata": {},
   "source": [
    "### Total 1D histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d5e51c-bd62-40d9-aab4-d0550f22def8",
   "metadata": {},
   "source": [
    "Below, we have the plots of the total 1D histograms for each band, meaning we are considering all input parquet files together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86767f2-bf3a-4fd8-992d-74afa6797d10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### General settings\n",
    "height = 400\n",
    "width = 400\n",
    "\n",
    "def setup_plot_data(band, histograms):\n",
    "    \"\"\"Sets the data to the plot for the specified band.\"\"\"\n",
    "    counts = histograms[band]['counts']\n",
    "    bin_edges = np.array(histograms[band]['bin_edges'])\n",
    "    bin_size = bin_edges[1] - bin_edges[0]\n",
    "    bin_edges = np.append(bin_edges, bin_edges[-1] + bin_size)\n",
    "    \n",
    "    max_count_index = histograms[band]['counts'].idxmax()\n",
    "    max_value = histograms[band].loc[max_count_index, 'bin_edges']\n",
    "    xlim = (max_value - 5, max_value + 5)\n",
    "\n",
    "    return counts, bin_edges, xlim\n",
    "\n",
    "def create_histogram(band, counts, bin_edges, xlim):\n",
    "    \"\"\"Creates the histogram using holoviews.\"\"\"\n",
    "    title = f'Distribution of Magnitudes - Band {band}'\n",
    "    label_name = f'mag {band}'\n",
    "    magnitudes = hv.Dimension(band, label=label_name)\n",
    "    mag_freqs = hv.Dimension(f'{band}_freqs', label=f'{label_name} freqs')\n",
    "    \n",
    "    return hv.Histogram((counts, bin_edges), kdims=magnitudes, vdims=mag_freqs).opts(\n",
    "        title=title, xlabel=label_name, ylabel='frequencies', height=height, width=width, xlim=xlim)\n",
    "\n",
    "### Preparing the histograms data.\n",
    "mag_distribution_histo = {}\n",
    "for band in bands_mag:\n",
    "    band = band.lower()\n",
    "    counts, bin_edges, xlim = setup_plot_data(band, total_mag_histograms)\n",
    "    mag_distribution_histo[band] = create_histogram(band, counts, bin_edges, xlim)\n",
    "\n",
    "### Composing the plots in a hv.Layout and showing.\n",
    "mag_distribution = hv.Layout([mag_distribution_histo[band] for band in bands_mag]).cols(2)\n",
    "mag_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f42a9a4-eb02-4d93-a43b-1db6d9fbfff0",
   "metadata": {},
   "source": [
    "### Individual 1D histograms for each input file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd39bcf-e004-410c-ada2-f75f3bc0ddcc",
   "metadata": {},
   "source": [
    "Now, in the plots below, for a given band, each light-colored curve was obtained from the 1D histogram of each individual Parquet file. The red curve, in turn, represents the mean value of counts in each bin, considering all input Parquet files.\n",
    "\n",
    "Note that if the histograms from each individual input file are very similar, meaning each input file has enough data so that statistical deviations are very small, **you may need to zoom in on the plot to distinguish the light curves, as they will all be very close to the average curve (red curve)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a4be50-b931-40be-b184-439058efe88d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Função ajustada para criar gráficos para um dataframe específico e banda\n",
    "def create_plot(df, bins, title, step=10):\n",
    "    curves = []\n",
    "    all_counts = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        counts = np.array(row['counts'])\n",
    "        all_counts.append(counts)\n",
    "        if i % step == 0:\n",
    "            centers = (bins[:-1] + bins[1:]) / 2\n",
    "            curve = hv.Curve((centers, counts), 'Magnitude', 'Counts').opts(line_width=2, alpha=0.3)\n",
    "            curves.append(curve)\n",
    "\n",
    "    mean_counts = np.mean(all_counts, axis=0)\n",
    "    mean_curve = hv.Curve((centers, mean_counts), 'Magnitude', 'Counts').opts(line_width=4, color='red').relabel('Mean Counts')\n",
    "\n",
    "    overlay = hv.Overlay(curves + [mean_curve]).opts(\n",
    "        hv.opts.Overlay(title=title, width=400, height=400, legend_position='top_left', show_legend=True, legend_limit=100),\n",
    "    )\n",
    "    return overlay\n",
    "\n",
    "# Criando gráficos para todas as bandas\n",
    "plots = []\n",
    "for band in bands_mag:\n",
    "    band_df = mag_histograms[band]\n",
    "    bins = np.array(mag_bins.loc[mag_bins['band'] == band, 'counts'].values[0])\n",
    "    plot = create_plot(band_df, bins, f\"Individual Files - Mag. Distrib. - Band {band}\", 50)\n",
    "    plots.append(plot)\n",
    "\n",
    "# Organizando todos os gráficos em um layout\n",
    "layout = hv.Layout(plots).opts(opts.Layout(shared_axes=False)).cols(2)\n",
    "\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cccb1b8-0e33-4e3c-b82d-01a225c1d5aa",
   "metadata": {},
   "source": [
    "# Magnitude errors distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f74b50-9cfc-4a88-b2d5-86f92e967fec",
   "metadata": {},
   "source": [
    "In the following subsections, we will read the data of the 1D histograms corresponding to the **magnitude errors distributions** and we will make plots for each band of the survey."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4199fcdb-9c6d-487d-a255-cc9bc7b87089",
   "metadata": {},
   "source": [
    "### How to get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3094d1ee-5d2f-4e8c-aca5-bf9172adef37",
   "metadata": {},
   "source": [
    "The file containing the data of the 1D histogram was obtained using High Performance Computing (HPC) in the LIneA Apollo Cluster. There is a Python script that reads all the input Parquet files and computes the 1D histogram. In this Python file, you can personalize the magnitude errors bin edges for each band. There is also an sbatch file used to submit the job to the cluster. They can be found in ```pz-compute/doc/dp02_qa_scripts/```.\n",
    "\n",
    "Files:\n",
    "1. Detailed instructions to run the scripts: ```DP02_QA_slurm_scripts_instructions.md```\n",
    "1. Python script: ```DP02_QA_histo_1d_magerr.py```\n",
    "2. Sbatch script: ```DP02_QA_histo_1d_magerr.sbatch```\n",
    "3. Resulting Parquet file containing the data: ```histo_1d_magerr_all_bands.parquet```\n",
    "\n",
    "For running the .py script in the cluster, you must follow the steps in the corresponding ```.md``` file.\n",
    "\n",
    "For this Jupyter notebook, the output file ```histo_1d_magerr_all_bands.parquet``` must be in the ```output``` folder, and this ```output``` folder must be in the same directory of the notebook itself.\n",
    "\n",
    "**For the magnitude errors distributions, we compute one 1D histogram for each input Parquet file, for each band. Given a certain band, we use the same bin edges for each input file.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a858e89f-3b0e-4d68-9d83-9c0af8368e6f",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d464cc3b-9cd5-4d64-afe0-1ae3ab613a8a",
   "metadata": {},
   "source": [
    "Below we can see the Parquet file structure. When the value of the 'filename' column is a path, the values of the 'counts' column are the 1D histogram counts for the file corresponding to this path. When the value of the 'filename' column is 'bins', the values of the 'counts' column are the bin edges used for each band.\n",
    "\n",
    "We also split, in the code lines, the original dataframe (df_magerr) into a list of dataframes containing only the 2D histograms counts (magerr_histograms), for each band, and a dataframe containing only the bins (magerr_bins), and we convert the values to numpy.arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7a16a9-ae62-49b5-b6bd-1dc8f10a6a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading the Parquet file.\n",
    "df_magerr = pd.read_parquet('output/histo_1d_magerr_all_bands.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a9d71d-669f-4a46-9e4c-7478ad0f73b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting the bands names and the number of bands.\n",
    "bands_magerr = df_magerr['band'].unique()\n",
    "num_of_bands_magerr = len(bands_magerr)\n",
    "\n",
    "### Separating the histograms of each band and the bin edges, and converting the lists to numpy arrays.\n",
    "magerr_histograms = {}\n",
    "for band in bands_magerr:\n",
    "    magerr_histograms[band] = df_magerr[df_magerr['band'] == band]\n",
    "    magerr_histograms[band] = magerr_histograms[band][magerr_histograms[band]['filename'] != 'bins']\n",
    "    magerr_histograms[band] = magerr_histograms[band].reset_index(drop=True)\n",
    "    magerr_histograms[band]['counts'] = magerr_histograms[band]['counts'].apply(np.array)\n",
    "\n",
    "magerr_bins = df_magerr[df_magerr['filename'] == 'bins']\n",
    "magerr_bins = magerr_bins.reset_index(drop=True)\n",
    "magerr_bins['counts'] = magerr_bins['counts'].apply(np.array)\n",
    "\n",
    "### Getting the input files names and the number of input files.\n",
    "filenames_paths_magerr = df_magerr['filename'].unique()\n",
    "filenames_paths_magerr = filenames_paths_magerr[filenames_paths_magerr!='bins']\n",
    "filenames_paths_magerr = filenames_paths_magerr.astype(str)\n",
    "filenames_magerr = np.char.replace(filenames_paths_magerr, '/lustre/t1/cl/lsst/dp02/secondary/catalogs/skinny/hdf5/', '')\n",
    "filenames_len_magerr = len(filenames_magerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f81301-eecb-4820-8002-09082cdf77fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRINTING THE INFORMATION\n",
    "### GENERAL INFORMATION\n",
    "print(f\"MAG. ERR. DIST. - NUMBER OF BANDS: {num_of_bands_magerr}\")\n",
    "print(f\"MAG. ERR. DIST. - BAND NAMES: {bands_magerr}\")\n",
    "print(f\"MAG. ERR. DIST. - NUMBER OF INPUT FILES: {filenames_len_magerr}\")\n",
    "print(f\"EACH BAND HAS A TOTAL OF {filenames_len_magerr} LINES, CORRESPONDING TO EACH INPUT FILE, PLUS ONE EXTRA LINE, CORRESPONDING TO THE BIN EDGES.\\n\")\n",
    "\n",
    "### INDIVIDUAL HISTOGRAMS PREVIEW\n",
    "printing_lines_for_each_band = 2\n",
    "print(f\"\\nPRINTING {printing_lines_for_each_band} LINES FOR EACH BAND, CONTAINING THE 1D HISTOGRAM COUNTS.\")\n",
    "for band in bands_magerr:\n",
    "    print(magerr_histograms[band].head(printing_lines_for_each_band))\n",
    "    print('\\n')\n",
    "\n",
    "### BIN EDGES PREVIEW\n",
    "print(f\"\\nPRINTING THE LINES CONTAINING THE BIN EDGES (THEY CAN BE FOUND AT THE END OF THE PARQUET FILE)\")\n",
    "print(magerr_bins.head())\n",
    "\n",
    "### BIN EDGES INFORMATION\n",
    "print(\"\\n\\nINFORMATION ABOUT THE BINS\")\n",
    "for band in bands_magerr:\n",
    "    bin_list = magerr_bins[magerr_bins['band']==band]['counts'].reset_index(drop=True)[0]\n",
    "    bin_min = bin_list.min()\n",
    "    bin_max = bin_list.max()\n",
    "    step = bin_list[1] - bin_list[0]\n",
    "    shape = bin_list.shape\n",
    "    print(f\"Min. bin edge - band {band}: {bin_min}\")\n",
    "    print(f\"Max. bin edge - band {band}: {bin_max}\")\n",
    "    print(f\"Step - band {band}: {step}\")\n",
    "    print(f\"Shape - band {band}: {shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e42a6b3-602b-421f-9027-096354e0a8a8",
   "metadata": {},
   "source": [
    "Now, we will compute the total 1D histogram for each band. This is done by summing the values in each bin for all the individual histograms. Below, we show some information about the total 1D histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eac39c-3b12-40cd-bf9d-37b046969a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Computing the total 1D histogram.\n",
    "total_magerr_histograms = {}\n",
    "for band in bands_magerr:\n",
    "    arrays = {}\n",
    "    num_of_rows = len(magerr_histograms[band].index)\n",
    "    for j in np.arange(0, num_of_rows, 1):\n",
    "        name = 'array'+str(j)\n",
    "        arrays[name] = magerr_histograms[band]['counts'][j]\n",
    "\n",
    "    somas = []\n",
    "\n",
    "    for elementos in zip(*arrays.values()):\n",
    "        soma = sum(elementos) \n",
    "        somas.append(soma)\n",
    "\n",
    "    data = {'counts': somas,\n",
    "            'bin_edges': magerr_bins.loc[magerr_bins['band'] == band, 'counts'].values[0][:-1]}\n",
    "\n",
    "    total_magerr_histograms[band] = pd.DataFrame(data)\n",
    "    \n",
    "### Printing the information.\n",
    "print(\"INFORMATION ABOUT THE TOTAL 1D HISTOGRAM COUNTS\")\n",
    "for band in bands_magerr:\n",
    "    print(f\"Min. count - band {band}: {total_magerr_histograms[band]['counts'].min()}\")\n",
    "    print(f\"Max. count - band {band}: {total_magerr_histograms[band]['counts'].max()}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3328f7f2-4a48-4013-af0e-291c72dd786d",
   "metadata": {},
   "source": [
    "## Magnitude errors distributions plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f78ba29-2ddf-4fc6-ba61-140c7c5cde6a",
   "metadata": {},
   "source": [
    "### Total 1D histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fa87ba-a739-4b87-8084-d03dfdf521ef",
   "metadata": {},
   "source": [
    "Below, we have the plots of the total 1D histograms for each band, meaning we are considering all input parquet files together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3fc93f-41c7-485d-b28f-dfffa3b2ceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### General settings\n",
    "height = 400\n",
    "width = 400\n",
    "\n",
    "def setup_plot_data(band, histograms):\n",
    "    \"\"\"Sets the data to the plot for the specified band.\"\"\"\n",
    "    counts = histograms[band]['counts']\n",
    "    bin_edges = np.array(histograms[band]['bin_edges'])\n",
    "    bin_size = bin_edges[1] - bin_edges[0]\n",
    "    bin_edges = np.append(bin_edges, bin_edges[-1] + bin_size)\n",
    "    \n",
    "    max_count_index = histograms[band]['counts'].idxmax()\n",
    "    max_value = histograms[band].loc[max_count_index, 'bin_edges']\n",
    "    xlim = (0, max_value + 0.5)\n",
    "\n",
    "    return counts, bin_edges, xlim\n",
    "\n",
    "def create_histogram(band, counts, bin_edges, xlim):\n",
    "    \"\"\"Creates the histogram using holoviews.\"\"\"\n",
    "    title = f'Distribution of Magnitude Errors - Band {band}'\n",
    "    label_name = f'magerr {band}'\n",
    "    magnitude_errors = hv.Dimension(band, label=label_name)\n",
    "    magerr_freqs = hv.Dimension(f'{band}_freqs', label=f'{label_name} freqs')\n",
    "    \n",
    "    return hv.Histogram((counts, bin_edges), kdims=magnitude_errors, vdims=magerr_freqs).opts(\n",
    "        title=title, xlabel=label_name, ylabel='frequencies', height=height, width=width, xlim=xlim)\n",
    "\n",
    "### Preparing the histograms data.\n",
    "magerr_distribution_histo = {}\n",
    "for band in bands_magerr:\n",
    "    band = band.lower()\n",
    "    counts, bin_edges, xlim = setup_plot_data(band, total_magerr_histograms)\n",
    "    magerr_distribution_histo[band] = create_histogram(band, counts, bin_edges, xlim)\n",
    "\n",
    "### Composing the plots in a hv.Layout and showing.\n",
    "magerr_distribution = hv.Layout([magerr_distribution_histo[band] for band in bands_magerr]).cols(2)\n",
    "magerr_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139a674b-d6e8-4dcf-aaa3-bd0df5e70e1b",
   "metadata": {},
   "source": [
    "### Individual 1D histograms for each input file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd232192-bf16-4b94-b618-076d0e87716f",
   "metadata": {},
   "source": [
    "Now, in the plots below, for a given band, each light-colored curve was obtained from the 1D histogram of each individual Parquet file. The red curve, in turn, represents the mean value of counts in each bin, considering all input Parquet files.\n",
    "\n",
    "Note that if the histograms from each individual input file are very similar, meaning each input file has enough data so that statistical deviations are very small, **you may need to zoom in on the plot to distinguish the light curves, as they will all be very close to the average curve (red curve)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e5d9c8-99ff-4514-85b8-854aafe93f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função ajustada para criar gráficos para um dataframe específico e banda\n",
    "def create_plot(df, bins, title, step=10):\n",
    "    curves = []\n",
    "    all_counts = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        counts = np.array(row['counts'])\n",
    "        all_counts.append(counts)\n",
    "        if i % step == 0:\n",
    "            centers = (bins[:-1] + bins[1:]) / 2\n",
    "            curve = hv.Curve((centers, counts), 'Magnitude Errors', 'Counts').opts(line_width=2, alpha=0.3)\n",
    "            curves.append(curve)\n",
    "\n",
    "    mean_counts = np.mean(all_counts, axis=0)\n",
    "    mean_curve = hv.Curve((centers, mean_counts), 'Magnitude Errors', 'Counts').opts(line_width=4, color='red').relabel('Mean Counts')\n",
    "\n",
    "    overlay = hv.Overlay(curves + [mean_curve]).opts(\n",
    "        hv.opts.Overlay(title=title, width=400, height=400, legend_position='top_left', show_legend=True, legend_limit=100),\n",
    "    )\n",
    "    return overlay\n",
    "\n",
    "# Criando gráficos para todas as bandas\n",
    "plots = []\n",
    "for band in bands_magerr:\n",
    "    band_df = magerr_histograms[band]\n",
    "    bins = np.array(magerr_bins.loc[magerr_bins['band'] == band, 'counts'].values[0])\n",
    "    plot = create_plot(band_df, bins, f\"Individual Files - Mag. Err. Distrib. - Band {band}\", 50)\n",
    "    plots.append(plot)\n",
    "\n",
    "# Organizando todos os gráficos em um layout\n",
    "layout = hv.Layout(plots).opts(opts.Layout(shared_axes=False)).cols(2)\n",
    "\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df811af-a17c-46dd-98f1-0a6afa7fa1b3",
   "metadata": {},
   "source": [
    "# Magnitude x Magnitude Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f64dac4-9404-4fd8-945b-6e0e6f3101ef",
   "metadata": {},
   "source": [
    "In the following subsections, we will read the data of the 2D histogram corresponding to the **Magnitude x Magnitude Error** plots, considering the magnitudes and magnitudes errors for each band.\n",
    "\n",
    "All graphs will also have a **colorbar** corresponding to the counts of objects per magnitude and magnitude error bin of the 2D histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a330bf6-ede3-4720-a259-62e216629e50",
   "metadata": {},
   "source": [
    "### How to get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51e433b-161a-4126-b628-88b92c07a7d9",
   "metadata": {},
   "source": [
    "The file containing the data of the 2D histogram was obtained using High Performance Computing (HPC) in the LIneA Apollo Cluster. There is a Python script that reads all the input Parquet files and computes the 2D histogram. In this Python file, you can personalize the magnitude and magnitude errors bin edges. There is also an sbatch file used to submit the job to the cluster. They can be found in ```pz-compute/doc/dp02_qa_scripts/```.\n",
    "\n",
    "Files:\n",
    "1. Detailed instructions to run the scripts: ```DP02_QA_slurm_scripts_instructions.md```\n",
    "1. Python script: ```DP02_QA_histo_2d_mag_magerr.py```\n",
    "2. Sbatch script: ```DP02_QA_histo_2d_mag_magerr.sbatch```\n",
    "3. Resulting Parquet file containing the data: ```histo_2d_mag_magerr_all_bands.parquet```\n",
    "\n",
    "For running the .py script in the cluster, you must follow the steps in the corresponding ```.md``` file.\n",
    "\n",
    "For this Jupyter notebook, the output file ```histo_2d_mag_magerr_all_bands.parquet``` must be in the ```output``` folder, and this ```output``` folder must be in the same directory of the notebook itself.\n",
    "\n",
    "**For the Magnitude x Magnitude Error plots, we do not compute one 2D histogram for each input Parquet file, just the total histogram considering all files together, for each band.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e05527f-c9de-4b7a-a8a1-62b12e45c29c",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ffb577-e27b-4a7b-b866-826645125fef",
   "metadata": {},
   "source": [
    "Below, we can see the output Parquet file structure and information about the bins. For each band, we have two lines, one for the 2D histogram counts, and other for the bins (mag_bins and magerr_bins).\n",
    "\n",
    "We also split, in the code lines, the original dataframe (df_mag_magerr) into a list of dataframes containing only the 2D histograms counts (mag_magerr_histograms), for each band, and a dataframe containing only the bins (mag_magerr_bins)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39190cd5-5f7d-4f01-9f8f-30d120118459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Reading the data.\n",
    "df_mag_magerr = pd.read_parquet('output/histo_2d_mag_magerr_all_bands.parquet', engine='fastparquet')\n",
    "\n",
    "### Getting the bands names and the number of bands.\n",
    "bands_mag_magerr = df_mag_magerr['band'].unique()\n",
    "num_of_bands_mag_magerr = len(bands_mag_magerr)\n",
    "\n",
    "### Separating the data of the counts into a different dataframe, and converting to numpy array.\n",
    "mag_magerr_histograms = {}\n",
    "for band in bands_mag_magerr:\n",
    "    mag_magerr_histograms[band] = df_mag_magerr[df_mag_magerr['band'] == band]\n",
    "    mag_magerr_histograms[band] = mag_magerr_histograms[band][mag_magerr_histograms[band]['type'] != 'bins']\n",
    "    mag_magerr_histograms[band] = mag_magerr_histograms[band].reset_index(drop=True)\n",
    "\n",
    "### Separating the data of the bins into a different dataframe, and converting to numpy array.  \n",
    "mag_magerr_bins = df_mag_magerr[df_mag_magerr['type'] == 'bins']\n",
    "mag_magerr_bins = mag_magerr_bins.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea33178a-65a9-4fec-8c80-4fed355e8c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mag_magerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badf08e7-4fdf-45f5-bbd3-0d9117eb0c21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### BIN EDGES INFORMATION\n",
    "print(\"\\n INFORMATION ABOUT THE BINS \\n\")\n",
    "for band in bands_mag_magerr:\n",
    "    bin_list = mag_magerr_bins[mag_magerr_bins['band']==band]['values'].reset_index(drop=True)[0]\n",
    "    \n",
    "    mag_bins = np.array(bin_list['mag_bins'])\n",
    "    bin_mag_min = mag_bins.min()\n",
    "    bin_mag_max = mag_bins.max()\n",
    "    step_mag = mag_bins[1] - mag_bins[0]\n",
    "    shape_mag = mag_bins.shape\n",
    "    \n",
    "    magerr_bins = np.array(bin_list['magerr_bins'])\n",
    "    bin_magerr_min = magerr_bins.min()\n",
    "    bin_magerr_max = magerr_bins.max()\n",
    "    step_magerr = magerr_bins[1] - magerr_bins[0]\n",
    "    shape_magerr = magerr_bins.shape\n",
    "    \n",
    "    print(f\"BAND {band}\")\n",
    "    print(f\"Min. mag bin edge: {bin_mag_min:.3f}\")\n",
    "    print(f\"Max. mag bin edge: {bin_mag_max:.3f}\")\n",
    "    print(f\"Step mag: {step_mag:.3f}\")\n",
    "    print(f\"Shape mag: {shape_mag}\\n\")\n",
    "    print(f\"Min. magerr bin edge: {bin_magerr_min:.4f}\")\n",
    "    print(f\"Max. magerr bin edge: {bin_magerr_max:.4f}\")\n",
    "    print(f\"Step magerr: {step_magerr:.4f}\")\n",
    "    print(f\"Shape magerr: {shape_magerr}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecebad6-b6c7-47fa-bdff-594fe617e272",
   "metadata": {},
   "source": [
    "## Magnitude x Magnitude Error plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a1bb3f-0e08-44b3-a7bf-91b98bf5191a",
   "metadata": {},
   "source": [
    "Before making the plots, we must perform some tasks:\n",
    "\n",
    "1. Change the 0 values in the 2D histogram counts array to NaN values, so that they appear white in the plot.\n",
    "2. Compute the centers of the bins.\n",
    "3. Transpose the 2D histogram counts arrays so that they become compatible with HoloViews/GeoViews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36840bb-5717-4544-b936-2244d651eb75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Converting the zero values to NaN in the 2D lists.\n",
    "def convert_zeros_to_nan(lst):\n",
    "    return [[np.nan if x == 0 else x for x in sublist] for sublist in lst]\n",
    "\n",
    "for band in mag_magerr_histograms:\n",
    "    mag_magerr_histograms[band]['values'] = mag_magerr_histograms[band]['values'].apply(convert_zeros_to_nan)\n",
    "\n",
    "### Computing the centers of the bins.\n",
    "x_edges = {}\n",
    "y_edges = {}\n",
    "\n",
    "for band in bands_mag_magerr:\n",
    "    mag_bins_vals = np.array(mag_magerr_bins.loc[mag_magerr_bins['band'] == band, 'values'].values[0]['mag_bins'])\n",
    "    magerr_bins_vals = np.array(mag_magerr_bins.loc[mag_magerr_bins['band'] == band, 'values'].values[0]['magerr_bins'])\n",
    "    \n",
    "    x_edges[band] = (mag_bins_vals[1:] + mag_bins_vals[:-1])/2\n",
    "    y_edges[band] = (magerr_bins_vals[1:] +  magerr_bins_vals[:-1])/2\n",
    "    \n",
    "### Transposing the histograms.\n",
    "histo = {}\n",
    "for band in bands_mag_magerr:\n",
    "    histo[band] = np.vstack(mag_magerr_histograms[band]['values'])   \n",
    "    histo[band] = histo[band].T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb04e372-7cdb-4e83-a04f-502e2a09ca4f",
   "metadata": {},
   "source": [
    "Finally, we have the Magnitude x Magnitude Error plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad801b6-a94c-4939-af01-84ce4ad74019",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "plots = []\n",
    "\n",
    "for band in bands_mag_magerr:\n",
    "    hv_image = hv.Image((x_edges[band], y_edges[band], histo[band]), [f'mag_{band}', f'magerr_{band}'], f'counts_{band}')\n",
    "    \n",
    "    hv_image = hv_image.opts(\n",
    "        opts.Image(cmap='viridis', cnorm='log', colorbar=True, width=600, height=400,\n",
    "                   xlim=(20, 27), ylim=(0, 0.2), tools=['hover'], clim=(10, np.max(histo[band])),\n",
    "                   title=f'Magnitude x Magnitude Error - Band {band}')\n",
    "    )\n",
    "    \n",
    "    plots.append(hv_image)\n",
    "\n",
    "# Organizando os gráficos em duas colunas\n",
    "layout = hv.Layout(plots).cols(2)\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2463f4c8-27df-45a6-bc1b-0b9610d19f2d",
   "metadata": {},
   "source": [
    "# Magnitude x Color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da93e8ed-20a9-4f77-a154-71ba33f66b73",
   "metadata": {},
   "source": [
    "In the following subsections, we will read the data of the 2D histogram corresponding to the **Magnitude x Color** plots.\n",
    "\n",
    "All graphs will also have a **colorbar** corresponding to the counts of objects per magnitude and color bin of the 2D histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce4702d-e2aa-4437-a455-f17573f8d8a3",
   "metadata": {},
   "source": [
    "### How to get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f968d4-9b89-439f-9608-341f2c858429",
   "metadata": {},
   "source": [
    "The file containing the data of the 2D histogram was obtained using High Performance Computing (HPC) in the LIneA Apollo Cluster. There is a Python script that reads all the input Parquet files and computes the 2D histogram. In this Python file, you can personalize the magnitude and colors graphs and bin edges. There is also an sbatch file used to submit the job to the cluster. They can be found in ```pz-compute/doc/dp02_qa_scripts/```.\n",
    "\n",
    "Files:\n",
    "1. Detailed instructions to run the scripts: ```DP02_QA_slurm_scripts_instructions.md```\n",
    "1. Python script: ```DP02_QA_histo_2d_mag_color.py```\n",
    "2. Sbatch script: ```DP02_QA_histo_2d_mag_color.sbatch```\n",
    "3. Resulting Parquet file containing the data: ```histo_2d_mag_color_all_graphs.parquet```\n",
    "\n",
    "For running the .py script in the cluster, you must follow the steps in the corresponding ```.md``` file.\n",
    "\n",
    "For this Jupyter notebook, the output file ```histo_2d_mag_color_all_graphs.parquet``` must be in the ```output``` folder, and this ```output``` folder must be in the same directory of the notebook itself.\n",
    "\n",
    "**For the Magnitude x Color plots, we do not compute one 2D histogram for each input Parquet file, just the total histogram considering all files together, for each graph.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3c0535-4390-4a58-866a-f5e60ca2deb4",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940a3249-4212-4c9c-a597-21e12232db56",
   "metadata": {},
   "source": [
    "Below, we can see the output Parquet file structure and information about the bins. For each graph, we have two lines, one for the 2D histogram counts, and other for the bins (mag_bins and color_bins).\n",
    "\n",
    "We also split, in the code lines, the original dataframe (df_mag_color) into a list of dataframes containing only the 2D histograms counts (mag_color_histograms), for each graph, and a dataframe containing only the bins (mag_color_bins)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeb356a-e8e1-4f50-bfd0-9d5865be3719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Reading the data.\n",
    "df_mag_color = pd.read_parquet('output/histo_2d_mag_color_all_graphs.parquet', engine='fastparquet')\n",
    "\n",
    "graphs = df_mag_color[\"graph\"].unique()\n",
    "\n",
    "### Separating the data of the counts into a different dataframe, and converting to numpy array.\n",
    "mag_color_histograms = {}\n",
    "for graph in graphs:\n",
    "    mag_color_histograms[graph] = df_mag_color[df_mag_color['graph'] == graph]\n",
    "    mag_color_histograms[graph] = mag_color_histograms[graph][mag_color_histograms[graph]['type'] != 'bins']\n",
    "    mag_color_histograms[graph] = mag_color_histograms[graph].reset_index(drop=True)\n",
    "\n",
    "### Separating the data of the bins into a different dataframe, and converting to numpy array.  \n",
    "mag_color_bins = df_mag_color[df_mag_color['type'] == 'bins']\n",
    "mag_color_bins = mag_color_bins.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45391ed6-648e-4c13-8385-17b7b80d1fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_mag_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d27d51e-da73-4180-b211-5b65a2c003a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### BIN EDGES INFORMATION\n",
    "print(\"\\n INFORMATION ABOUT THE BINS \\n\")\n",
    "for graph in graphs:\n",
    "    bin_list = mag_color_bins[mag_color_bins['graph']==graph]['values'].reset_index(drop=True)[0]\n",
    "    \n",
    "    mag_bins = np.array(bin_list['mag_bins'])\n",
    "    bin_mag_min = mag_bins.min()\n",
    "    bin_mag_max = mag_bins.max()\n",
    "    step_mag = mag_bins[1] - mag_bins[0]\n",
    "    shape_mag = mag_bins.shape\n",
    "    \n",
    "    color_bins = np.array(bin_list['color_bins'])\n",
    "    bin_color_min = color_bins.min()\n",
    "    bin_color_max = color_bins.max()\n",
    "    step_color = color_bins[1] - color_bins[0]\n",
    "    shape_color = color_bins.shape\n",
    "    \n",
    "    print(f\"GRAPH {graph}\")\n",
    "    print(f\"Min. mag bin edge: {bin_mag_min:.3f}\")\n",
    "    print(f\"Max. mag bin edge: {bin_mag_max:.3f}\")\n",
    "    print(f\"Step mag: {step_mag:.3f}\")\n",
    "    print(f\"Shape mag: {shape_mag}\\n\")\n",
    "    print(f\"Min. color bin edge: {bin_color_min:.4f}\")\n",
    "    print(f\"Max. color bin edge: {bin_color_max:.4f}\")\n",
    "    print(f\"Step color: {step_color:.4f}\")\n",
    "    print(f\"Shape color: {shape_color}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1441bb-11d2-4a33-a704-a97d7e0838af",
   "metadata": {},
   "source": [
    "## Magnitude x Color plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fa90f2-aeb5-46bd-a4ff-8955ff18a735",
   "metadata": {},
   "source": [
    "Before making the plots, we must perform some tasks:\n",
    "\n",
    "1. Change the 0 values in the 2D histogram counts array to NaN values, so that they appear white in the plot.\n",
    "2. Compute the centers of the bins.\n",
    "3. Transpose the 2D histogram counts arrays so that they become compatible with HoloViews/GeoViews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21fa0ff-0bea-48ed-b249-4a0a32f24c4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Converting the zero values to NaN in the 2D lists.\n",
    "def convert_zeros_to_nan(lst):\n",
    "    return [[np.nan if x == 0 else x for x in sublist] for sublist in lst]\n",
    "\n",
    "for graph in mag_color_histograms:\n",
    "    mag_color_histograms[graph]['values'] = mag_color_histograms[graph]['values'].apply(convert_zeros_to_nan)\n",
    "\n",
    "### Computing the centers of the bins.\n",
    "x_edges = {}\n",
    "y_edges = {}\n",
    "\n",
    "for graph in graphs:\n",
    "    mag_bins_vals = np.array(mag_color_bins.loc[mag_color_bins['graph'] == graph, 'values'].values[0]['mag_bins'])\n",
    "    color_bins_vals = np.array(mag_color_bins.loc[mag_color_bins['graph'] == graph, 'values'].values[0]['color_bins'])\n",
    "    \n",
    "    x_edges[graph] = (mag_bins_vals[1:] + mag_bins_vals[:-1])/2\n",
    "    y_edges[graph] = (color_bins_vals[1:] +  color_bins_vals[:-1])/2\n",
    "    \n",
    "### Transposing the histograms.\n",
    "histo = {}\n",
    "for graph in graphs:\n",
    "    histo[graph] = np.vstack(mag_color_histograms[graph]['values'])   \n",
    "    histo[graph] = histo[graph].T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5ecf3c-e574-4f0b-bd32-1ec718f1445a",
   "metadata": {},
   "source": [
    "Finally, we have the Magnitude x Color plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e32c531-2edc-4aa1-97cc-6392c707b857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "plots = []\n",
    "\n",
    "i=0\n",
    "for graph in graphs:\n",
    "    band, color = graph.split('_x_')\n",
    "    \n",
    "    hv_image = hv.Image((x_edges[graph], y_edges[graph], histo[graph]), [f'{i}_mag_{band}', f'{i}_color_{color}'], f'{i}_counts_{graph}')\n",
    "    \n",
    "    hv_image = hv_image.opts(\n",
    "        opts.Image(cmap='viridis', cnorm='log', colorbar=True, width=600, height=400,\n",
    "                   xlim=(15, 28), ylim=(-2, 2), tools=['hover'], clim=(10, np.max(histo[graph])),\n",
    "                   title=f'Magnitude x Color - Band {band} vs Color {color}')\n",
    "    )\n",
    "    \n",
    "    plots.append(hv_image)\n",
    "    i+=1\n",
    "\n",
    "# Organizando os gráficos em duas colunas\n",
    "layout = hv.Layout(plots).cols(2)\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c7767d-d050-41e2-8f73-5875685e6e80",
   "metadata": {},
   "source": [
    "# Color x Color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ba1806-4781-4bae-9685-b99a0fe91221",
   "metadata": {},
   "source": [
    "In the following subsections, we will read the data of the 2D histogram corresponding to the **Color x Color** plots.\n",
    "\n",
    "All graphs will also have a **colorbar** corresponding to the counts of objects per color 1 and color 2 bin of the 2D histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fac988-9858-45b1-887f-535e9dd8d399",
   "metadata": {},
   "source": [
    "### How to get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0051a32c-19bb-4455-9b7e-c4e7159fb08f",
   "metadata": {},
   "source": [
    "The file containing the data of the 2D histogram was obtained using High Performance Computing (HPC) in the LIneA Apollo Cluster. There is a Python script that reads all the input Parquet files and computes the 2D histogram. In this Python file, you can personalize the color x color graphs and bin edges. There is also an sbatch file used to submit the job to the cluster. They can be found in ```pz-compute/doc/dp02_qa_scripts/```.\n",
    "\n",
    "Files:\n",
    "1. Detailed instructions to run the scripts: ```DP02_QA_slurm_scripts_instructions.md```\n",
    "2. Python script: ```DP02_QA_histo_2d_color_color.py```\n",
    "3. Sbatch script: ```DP02_QA_histo_2d_color_color.sbatch```\n",
    "4. Resulting Parquet file containing the data: ```histo_2d_color_color_all_graphs.parquet```\n",
    "\n",
    "For running the .py script in the cluster, you must follow the steps in the corresponding ```.md``` file.\n",
    "\n",
    "For this Jupyter notebook, the output file ```histo_2d_color_color_all_graphs.parquet``` must be in the ```output``` folder, and this ```output``` folder must be in the same directory of the notebook itself.\n",
    "\n",
    "**For the Color x Color plots, we do not compute one 2D histogram for each input Parquet file, just the total histogram considering all files together, for each graph.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ea79b3-8591-41cd-86c7-fd0de0c2ba40",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dbf4ff-3b29-47f9-9e0b-9592a1c2831a",
   "metadata": {},
   "source": [
    "Below, we can see the output Parquet file structure and information about the bins. For each graph, we have two lines, one for the 2D histogram counts, and other for the bins (color1_bins and color2_bins).\n",
    "\n",
    "We also split, in the code lines, the original dataframe (df_color_color) into a list of dataframes containing only the 2D histograms counts (color_color_histograms), for each graph, and a dataframe containing only the bins (color_color_bins)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edc9ce9-ddce-4fb5-83bf-eecd35f03968",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading the data.\n",
    "df_color_color = pd.read_parquet('output/histo_2d_color_color_all_graphs.parquet', engine='fastparquet')\n",
    "\n",
    "graphs_color_color = df_color_color[\"graph\"].unique()\n",
    "\n",
    "### Separating the data of the counts into a different dataframe, and converting to numpy array.\n",
    "color_color_histograms = {}\n",
    "for graph in graphs_color_color:\n",
    "    color_color_histograms[graph] = df_color_color[df_color_color['graph'] == graph]\n",
    "    color_color_histograms[graph] = color_color_histograms[graph][color_color_histograms[graph]['type'] != 'bins']\n",
    "    color_color_histograms[graph] = color_color_histograms[graph].reset_index(drop=True)\n",
    "\n",
    "### Separating the data of the bins into a different dataframe, and converting to numpy array.  \n",
    "color_color_bins = df_color_color[df_color_color['type'] == 'bins']\n",
    "color_color_bins = color_color_bins.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b477954-935b-4176-b385-b9e2171cb429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_color_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bab7a3-fb86-4851-b7eb-ccf67565fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BIN EDGES INFORMATION\n",
    "print(\"\\n INFORMATION ABOUT THE BINS \\n\")\n",
    "for graph in graphs_color_color:\n",
    "    bin_list = color_color_bins[color_color_bins['graph']==graph]['values'].reset_index(drop=True)[0]\n",
    "    \n",
    "    color1_bins = np.array(bin_list['color1_bins'])\n",
    "    bin_color1_min = color1_bins.min()\n",
    "    bin_color1_max = color1_bins.max()\n",
    "    step_color1 = color1_bins[1] - color1_bins[0]\n",
    "    shape_color1 = color1_bins.shape\n",
    "    \n",
    "    color2_bins = np.array(bin_list['color2_bins'])\n",
    "    bin_color2_min = color2_bins.min()\n",
    "    bin_color2_max = color2_bins.max()\n",
    "    step_color2 = color2_bins[1] - color2_bins[0]\n",
    "    shape_color2 = color2_bins.shape\n",
    "    \n",
    "    print(f\"GRAPH {graph}\")\n",
    "    print(f\"Min. color1 bin edge: {bin_color1_min:.3f}\")\n",
    "    print(f\"Max. color1 bin edge: {bin_color1_max:.3f}\")\n",
    "    print(f\"Step color1: {step_color1:.3f}\")\n",
    "    print(f\"Shape color1: {shape_color1}\\n\")\n",
    "    print(f\"Min. color2 bin edge: {bin_color2_min:.4f}\")\n",
    "    print(f\"Max. color2 bin edge: {bin_color2_max:.4f}\")\n",
    "    print(f\"Step color2: {step_color2:.4f}\")\n",
    "    print(f\"Shape color2: {shape_color2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1b3821-de95-49ab-b489-dcaacde13eab",
   "metadata": {},
   "source": [
    "## Color x Color plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc03cc5-5254-4cd5-87b0-7ace5399bf3c",
   "metadata": {},
   "source": [
    "Before making the plots, we must perform some tasks:\n",
    "\n",
    "1. Change the 0 values in the 2D histogram counts array to NaN values, so that they appear white in the plot.\n",
    "2. Compute the centers of the bins.\n",
    "3. Transpose the 2D histogram counts arrays so that they become compatible with HoloViews/GeoViews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1062561-4e87-4276-98e2-3d71ac638fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Converting the zero values to NaN in the 2D lists.\n",
    "def convert_zeros_to_nan(lst):\n",
    "    return [[np.nan if x == 0 else x for x in sublist] for sublist in lst]\n",
    "\n",
    "for graph in color_color_histograms:\n",
    "    color_color_histograms[graph]['values'] = color_color_histograms[graph]['values'].apply(convert_zeros_to_nan)\n",
    "\n",
    "### Computing the centers of the bins.\n",
    "x_edges = {}\n",
    "y_edges = {}\n",
    "\n",
    "for graph in graphs_color_color:\n",
    "    color1_bins_vals = np.array(color_color_bins.loc[color_color_bins['graph'] == graph, 'values'].values[0]['color1_bins'])\n",
    "    color2_bins_vals = np.array(color_color_bins.loc[color_color_bins['graph'] == graph, 'values'].values[0]['color2_bins'])\n",
    "    \n",
    "    x_edges[graph] = (color1_bins_vals[1:] + color1_bins_vals[:-1])/2\n",
    "    y_edges[graph] = (color2_bins_vals[1:] +  color2_bins_vals[:-1])/2\n",
    "    \n",
    "### Transposing the histograms.\n",
    "histo = {}\n",
    "for graph in graphs_color_color:\n",
    "    histo[graph] = np.vstack(color_color_histograms[graph]['values'])   \n",
    "    histo[graph] = histo[graph].T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1612121-42f1-4421-b720-940d836488f6",
   "metadata": {},
   "source": [
    "Finally, we have the Color x Color plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41bc7bc-7b66-4f27-88db-45eda185a482",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plots = []\n",
    "\n",
    "i=0\n",
    "for graph in graphs_color_color:\n",
    "    color1, color2 = graph.split('_x_')\n",
    "    \n",
    "    hv_image = hv.Image((x_edges[graph], y_edges[graph], histo[graph]), [f'{i}_color_{color1}', f'{i}_color_{color2}'], f'{i}_counts_{graph}')\n",
    "    \n",
    "    hv_image = hv_image.opts(\n",
    "        opts.Image(cmap='viridis', cnorm='log', colorbar=True, width=600, height=400,\n",
    "                   xlim=(-6, 6), ylim=(-6, 6), tools=['hover'], clim=(10, np.max(histo[graph])),\n",
    "                   title=f'Color x Color - {color1} vs {color2}')\n",
    "    )\n",
    "    \n",
    "    plots.append(hv_image)\n",
    "    i+=1\n",
    "# Organizando os gráficos em duas colunas\n",
    "layout = hv.Layout(plots).cols(2)\n",
    "layout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hv-bokeh-upd",
   "language": "python",
   "name": "hv-bokeh-upd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04e9acd5-d690-465b-9f5d-c3ab854e6d0e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img align=\"left\" src = https://linea.org.br/wp-content/themes/LIneA/imagens/logo-header.jpg width=130 style=\"padding: 20px\"> \n",
    "\n",
    "# PZ-Validation output with using RAIL\n",
    "\n",
    "   **Contact**: Heloisa da S. Mengisztki, Julia Gschwend<br>\n",
    "   **Last verified run**: 2024-june <br><br><br>\n",
    "\n",
    "QA created to validate the quality of outputs produced by LIneA PZ-Compute pipeline, documentedin the Stage III - Photo-z computing in [S4.4 - PZ Tables as Federated Datasets](https://linea-it.github.io/pz-lsst-inkind-doc/s4_4/). This notebook was based on the notebooks present in the rail documentation \"Goldenspike\", \"Evaluation_by_type\" and \"Evaluation_Demo\", which can be found in the Rail repository available at [Rail-Github](https://github.com/LSSTDESC/rail). Reference notebooks authors: RAIL team.\n",
    "\n",
    "### Table of Contents\n",
    "1. [Imports](#Imports)\n",
    "2. [Reading the files](#Reading-the-files)\n",
    "3. [Metrics Validation](#Metrics-Validation )\n",
    "   - Sumarry Statistics\n",
    "   - CDF based Metrics\n",
    "4. [Plots](#Plots)\n",
    "   - Redshift stacked distribution of the pdfs\n",
    "   - Zphot vs. Ztrue\n",
    "   - QQ Plot\n",
    "   - KS Plot\n",
    "5. [Summarized Metrics](#Summarized-Metrics)\n",
    "\n",
    "-----\n",
    "\n",
    "### Observations and Pre requisites\n",
    "\n",
    "- Have a rail environment and kernel \n",
    "\n",
    "> Rail Install: https://rail-hub.readthedocs.io/en/latest/source/installation.html <br/>\n",
    "> To install rail was needed to run the folowing command and in the apl cluster `CFLAGS=\"-O2 -std=gnu99\" pip install pytdigest`\n",
    "> In a short way, it changes the version for the default C used\n",
    "\n",
    "- Have a validation set and the true z. You can use pz-server to dowload a validation set and ztrue files with the id `72_pzcompute_results_for_qa_validation`\n",
    "> Util command to read the output file in the terminal if necessary\n",
    "> `h5dump -H output1.hdf5`\n",
    "\n",
    "- Copy file utils.py from [rail](https://github.com/LSSTDESC/rail/blob/main/examples/evaluation_examples/utils.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514433c9-3f74-4c39-a7c5-d1327b3ca7c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da70e609-6e4a-43e1-b4da-17c7572d6b36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pre-requisites\n",
    "import os\n",
    "import numpy as np\n",
    "import tables_io\n",
    "import qp \n",
    "import os\n",
    "##import holoviews as hv\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "from pathlib import Path\n",
    "#hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c52d24-2e5e-4312-a0bd-11571d87974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rail modules\n",
    "import rail\n",
    "\n",
    "from rail.core.data import TableHandle, QPHandle, Hdf5Handle, PqHandle\n",
    "from rail.core.stage import RailStage\n",
    "from rail.core.util_stages import ColumnMapper, TableConverter\n",
    "from rail.core.utils import find_rail_file\n",
    "\n",
    "from rail.estimation.algos.naive_stack import NaiveStackSummarizer\n",
    "from rail.estimation.algos.point_est_hist import PointEstHistSummarizer\n",
    "\n",
    "from rail.evaluation.dist_to_dist_evaluator import DistToDistEvaluator # pdfs true vs pdfs caldulada\n",
    "from rail.evaluation.dist_to_point_evaluator import DistToPointEvaluator # zmode calculado vs pdfs true\n",
    "from rail.evaluation.point_to_point_evaluator import PointToPointEvaluator # zmode true vs zmode calculado\n",
    "from rail.evaluation.single_evaluator import SingleEvaluator\n",
    "from rail.evaluation.evaluator import OldEvaluator\n",
    "\n",
    "from rail.evaluation.metrics.cdeloss import *\n",
    "from rail.evaluation.metrics.pointestimates import PointSigmaIQR, PointBias, PointOutlierRate, PointSigmaMAD, PointStatsEz\n",
    "\n",
    "from utils import plot_pit_qq, ks_plot, read_pz_output, plot_pdfs, plot_old_valid, old_metrics_table #copied utils.py from rail/examples/evaluation_examples\n",
    "\n",
    "from qp.metrics.pit import PIT\n",
    " \n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e447e3-254d-4394-9ed1-47580ea2bc01",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reading the files\n",
    "\n",
    "Here we are going to load the files and have a look trough the output file of a pz-estimate to better undestand the structure of the output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408f6c3c-bdd6-4766-a023-dda32f18ce38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_set_output_path = '/home/heloisa.mengisztki/software/Issue43/validation_set_output.hdf5'\n",
    "validation_set_path = '/home/heloisa.mengisztki/software/Issue43/validation_set.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e4dbe5-36c9-4532-8c26-724c457412f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdfs_file_output = find_rail_file(validation_set_output_path)\n",
    "table = tables_io.read(pdfs_file_output, fmt='hdf5')\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5c720f-7e71-4478-838d-37da447360c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Adding Zmode to the output\n",
    "\n",
    "Adding the mode of the pdf generated for each object in the file, each zmode is equivalent to the photoz calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5561ac-0972-4881-b664-9c137d98178c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'ancil' in table:\n",
    "    if 'zmode' in table['ancil']:\n",
    "        print('file already has zmodes')\n",
    "else:\n",
    "    print('inserting zmodes')\n",
    "    def zmode(df):\n",
    "        results = []\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            #mode_y = row.max()\n",
    "            mode_x = row.idxmax()\n",
    "            results.append(mode_x/100)\n",
    "\n",
    "        return results\n",
    "\n",
    "    zvalues_df = pd.DataFrame(table['data']['yvals'])\n",
    "\n",
    "    z_modes = zmode(zvalues_df)\n",
    "\n",
    "    def write_hdf5_file(file_name, z_modes):\n",
    "        with h5py.File(file_name, 'r+') as hdf5_file:\n",
    "            photometry_group = hdf5_file.create_group('ancil')\n",
    "            photometry_group['zmode'] = z_modes\n",
    "\n",
    "    write_hdf5_file(pdfs_file_output, z_modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f62b43-dbc5-49dd-b791-297f0f05ae7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_pdfs = DS.read_file(pdfs_file_output, QPHandle, pdfs_file_output)\n",
    "output_pdfs().build_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb29cde-f525-4fbe-8065-6f69b650dbf2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reading the Truth table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dfb1f2-cd5a-4164-a161-a4d84144682b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ztrue_file = find_rail_file(validation_set_path)\n",
    "ztrue_data = DS.read_file('ztrue_data', TableHandle, ztrue_file)\n",
    "\n",
    "truth = tables_io.convertObj(ztrue_data(), tables_io.types.PD_DATAFRAME)\n",
    "truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9697079-4ce3-456e-8c94-53afca095533",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"ztrue com {len(truth)} objetos\")\n",
    "print(f\"pdfs output com {len(output_pdfs().build_tables()['data']['yvals'])} objetos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b51f49-048b-475b-8f8a-5298cf7dbf79",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ploting some objects to see the pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038270c0-2f3b-497e-aee7-9916d5e519bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_vals = output_pdfs().metadata()['xvals'] #the photoz bins\n",
    "y_vals = output_pdfs().build_tables()['data']['yvals'] #the pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bcc80f-2589-4151-9150-eb3cbbeaf7da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zvalues_df = pd.DataFrame(y_vals)\n",
    "print(f\"Outputs com {len(zvalues_df)} objetos\")\n",
    "zvalues_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b85925-fa8b-4c50-9c1c-f84302247562",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "gs = fig.add_gridspec(3, hspace=0)\n",
    "axs = gs.subplots(sharex=True, sharey=True)\n",
    "fig.suptitle('pdf values for 3 objects')\n",
    "axs[0].plot(x_vals[0], y_vals[1])\n",
    "axs[1].plot(x_vals[0], y_vals[2])\n",
    "axs[2].plot(x_vals[0], y_vals[3])\n",
    "\n",
    "axs[2].set_xlabel(\"redshift\")\n",
    "axs[1].set_ylabel(\"fzboost pdfs\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.label_outer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0733bc06-d0f6-48e2-997d-27165236ff66",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Metrics Validation \n",
    "\n",
    "Here we are going to calculate some metrics to validate the quality of the estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388b73e0-88a7-41bc-b5ce-8c1bad6b7b80",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Point to point metrics - Sumary statistics\n",
    "\n",
    "1. point_stats_iqr: 'Interquatile range from 0.25 to 0.75', i.e., the middle 50% of the distribution of point_stats_ez, robust to outliers\n",
    "2. point_bias: Median of point_stats_ez\n",
    "3. point_outlier_rate: Calculates the catastrophic outlier rate, defined in the Science Book as the number of galaxies with ez larger than max(0.06,3sigma). This keeps the fraction reasonable when sigma is very small.\n",
    "4. point_stats_sigma_mad: Sigma of the median absolute deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdddfdc-8367-4633-8b34-ebb8870d8173",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_dict = dict(\n",
    "    metrics=['point_stats_ez', 'point_stats_iqr', 'point_bias', 'point_outlier_rate', 'point_stats_sigma_mad'],\n",
    "    _random_state=None,\n",
    "    hdf5_groupname='photometry',\n",
    "    point_estimate_key='zmode',\n",
    "    chunk_size=10000,\n",
    "    metric_config={\n",
    "        'point_stats_iqr':{'tdigest_compression': 100},\n",
    "    }\n",
    ")\n",
    "ptp_stage = PointToPointEvaluator.make_stage(name='point_to_point', **stage_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb981d18-461d-48c6-a248-e725cfb4f78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptp_results = ptp_stage.evaluate(output_pdfs, ztrue_data)\n",
    "ptp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257bd988-ccd9-46ef-aae6-b26a92e55319",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = tables_io.convertObj(ptp_results['summary'](), tables_io.types.PD_DATAFRAME)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd0c956-7c0d-44b1-835e-a770aa59d74a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dist to point metrics - CDF based Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bb67f0-5895-44d3-a85a-21c6258a0a89",
   "metadata": {},
   "source": [
    "1. cdeloss: [Conditional Density Estimation](https://vitaliset.github.io/conditional-density-estimation/)\n",
    "2. pit: [Probability Integral Transform](https://en.wikipedia.org/wiki/Probability_integral_transform)\n",
    "3. cvm: [Cramer-von Mises](https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93von_Mises_criterion)\n",
    "4. ks: [Kolmogorov-Smirnov](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test)\n",
    "5. ad: [Anderson-Darling](https://en.wikipedia.org/wiki/Anderson%E2%80%93Darling_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17936ca7-6ad3-4d0f-970b-baeb2ed1ad3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CDE Loss\n",
    "\n",
    "In the absence of true photo-z posteriors, the metric used to evaluate individual PDFs is the **Conditional Density Estimate (CDE) Loss**, a metric analogue to the root-mean-squared-error:\n",
    "\n",
    "$$ L(f, \\hat{f}) \\equiv  \\int \\int {\\big(f(z | x) - \\hat{f}(z | x) \\big)}^{2} dzdP(x), $$ \n",
    "\n",
    "where $f(z | x)$ is the true photo-z PDF and $\\hat{f}(z | x)$ is the estimated PDF in terms of the photometry $x$. Since $f(z | x)$  is unknown, we estimate the **CDE Loss** as described in [Izbicki & Lee, 2017 (arXiv:1704.08095)](https://arxiv.org/abs/1704.08095). :\n",
    "\n",
    "$$ \\mathrm{CDE} = \\mathbb{E}\\big(  \\int{{\\hat{f}(z | X)}^2 dz} \\big) - 2{\\mathbb{E}}_{X, Z}\\big(\\hat{f}(Z, X) \\big) + K_{f},  $$\n",
    "\n",
    "\n",
    "where the first term is the expectation value of photo-z posterior with respect to the marginal distribution of the covariates X, and the second term is the expectation value  with respect to the joint distribution of observables X and the space Z of all possible redshifts (in practice, the centroids of the PDF bins), and the third term is a constant depending on the true conditional densities $f(z | x)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca40c22-b485-4bab-b345-c3d150a73690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdelossobj = CDELoss(output_pdfs.data, output_pdfs().metadata()['xvals'].ravel(), ztrue_data()['redshift'])\n",
    "\n",
    "cde_stat_and_pval = cdelossobj.evaluate()\n",
    "print(cde_stat_and_pval)\n",
    "print(f\"CDE loss of this sample: {cde_stat_and_pval.statistic:.2f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f140d3f4-c916-49b6-ba6e-263f07483160",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PIT\n",
    "\n",
    "The [Probability Integral Transform](https://en.wikipedia.org/wiki/Probability_integral_transform) (PIT), is the Cumulative Distribution Function (CDF) of the photo-z PDF \n",
    "\n",
    "$$ \\mathrm{CDF}(f, q)\\ =\\ \\int_{-\\infty}^{q}\\ f(z)\\ dz $$\n",
    "\n",
    "evaluated at the galaxy's true redshift for every galaxy $i$ in the catalog.\n",
    "\n",
    "$$ \\mathrm{PIT}(p_{i}(z);\\ z_{i})\\ =\\ \\int_{-\\infty}^{z^{true}_{i}}\\ p_{i}(z)\\ dz $$ \n",
    "\n",
    "Probability integrated transform, 𝑃𝐼𝑇 (𝑧phot) = ∫𝑧phot 0 𝑃 (𝑧) 𝑑𝑧, calculated for all test galaxies, should be flat for well-estimated 𝑃 (𝑧) (Polsterer et al., 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629407b5-4731-4278-8c50-7906d3ab5594",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pitobj = PIT(output_pdfs(), ztrue_data()['redshift'])\n",
    "\n",
    "pit_out_rate = pitobj.evaluate_PIT_outlier_rate()\n",
    "print(f\"PIT outlier rate of this sample: {pit_out_rate:.6f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d55a67a-9bd5-4b20-8ecd-6d1049308547",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Kolmogorov-Smirnov  \n",
    "\n",
    "Let's start with the traditional Kolmogorov-Smirnov (KS) statistic test, which is the maximum difference between the empirical and the expected cumulative distributions of PIT values:\n",
    "\n",
    "$$\n",
    "\\mathrm{KS} \\equiv \\max_{PIT} \\Big( \\left| \\ \\mathrm{CDF} \\small[ \\hat{f}, z \\small] - \\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\  \\right| \\Big)\n",
    "$$\n",
    "\n",
    "Where $\\hat{f}$ is the PIT distribution and $\\tilde{f}$ is U(0,1). Therefore, the smaller value of KS the closer the PIT distribution is to be uniform. The `evaluate` method of the PITKS class returns a named tuple with the statistic and p-value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1955b4f5-9527-4cfb-9751-17f6abbac7ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ks_stat_and_pval = pitobj.evaluate_PIT_KS()\n",
    "print(f\"PIT KS stat and pval: {ks_stat_and_pval}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c7347a-5a73-4424-a7a1-83bc332f2290",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cramer-von Mises\n",
    "\n",
    "Similarly, let's calculate the Cramer-von Mises (CvM) test, a variant of the KS statistic defined as the mean-square difference between the CDFs of an empirical PDF and the true PDFs:\n",
    "\n",
    "$$ \\mathrm{CvM}^2 \\equiv \\int_{-\\infty}^{\\infty} \\Big( \\mathrm{CDF} \\small[ \\hat{f}, z \\small] \\ - \\ \\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\Big)^{2} \\mathrm{dCDF}(\\tilde{f}, z) $$ \n",
    "\n",
    "on the distribution of PIT values, which should be uniform if the PDFs are perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba66aa-ee12-4830-acef-a77f59686b95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cvm_stat_and_pval = pitobj.evaluate_PIT_CvM()\n",
    "print(f\"PIT CvM stat and pval: {cvm_stat_and_pval}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c47d77b-1847-485b-ac65-620477c20f12",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Anderson-Darling \n",
    "\n",
    "Another variation of the KS statistic is the Anderson-Darling (AD) test, a weighted mean-squared difference featuring enhanced sensitivity to discrepancies in the tails of the distribution. \n",
    "\n",
    "$$ \\mathrm{AD}^2 \\equiv N_{tot} \\int_{-\\infty}^{\\infty} \\frac{\\big( \\mathrm{CDF} \\small[ \\hat{f}, z \\small] \\ - \\ \\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\big)^{2}}{\\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\big( 1 \\ - \\ \\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\big)}\\mathrm{dCDF}(\\tilde{f}, z) $$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a63f43d-23b9-4262-988c-b32397d9e5a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ad_stat_crit_sig = pitobj.evaluate_PIT_anderson_ksamp()\n",
    "print(f\"PIT AD stat and pval: {ad_stat_crit_sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63050508-1586-4dac-8bf7-dcbf489db198",
   "metadata": {},
   "source": [
    "It is possible to remove catastrophic outliers before calculating the integral for the sake of preserving numerical instability. For instance, Schmidt et al. computed the Anderson-Darling statistic within the interval (0.01, 0.99)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325f86a5-f9f5-48fc-b36a-eb47a79cf68f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ad_stat_crit_sig_cut = pitobj.evaluate_PIT_anderson_ksamp(pit_min=0.01, pit_max=0.99)\n",
    "print(f\"AD metric for 0.01 < PIT < 0.99 and pval: {ad_stat_crit_sig_cut}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c88bbe-cd5e-4b16-a927-4b354f8f9e02",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0b5fd6-fef4-4e47-aa01-0688d8f82c67",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Redshift stacked distribution of the pdfs\n",
    "Summarized the per-galaxy redshift constraints to make population-level distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e9559-3d0f-4bd6-bc89-a84cced08e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_estimate_test = PointEstHistSummarizer.make_stage(name=\"point_estimate_test\")\n",
    "naive_stack_test = NaiveStackSummarizer.make_stage(name=\"naive_stack_test\")\n",
    "\n",
    "point_estimate_ens = point_estimate_test.summarize(output_pdfs)\n",
    "naive_stack_ens = naive_stack_test.summarize(output_pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97b4fce-2798-42c4-a1ac-960e42ce36e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = naive_stack_ens.data.plot_native(xlim=(0, 3)) #pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df629e0b-2dc6-4540-9dce-fb9b14fad35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = point_estimate_ens.data.plot_native(xlim=(0, 3)) #zmode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d8bcae-32e4-4ec7-ac9d-6b117912b689",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Zphot vs. Ztrue\n",
    "\n",
    "This plot is a scatter plot that compares two types of redshift measurements: photometric redshift estimated (\"photoz\") and spectroscopic redshift (\"specz\") representing the true redshift\n",
    "\n",
    "The red dashed line is the 1:1 line where photoz would equal specz. This line represents perfect agreement between the two measurements. Therefore the scatter around the red line suggests that, on average, the photoz estimates are reasonably accurate but with some variation. Less scatter indicates better agreement. Systematic deviations or patterns can also appear compared to the red line when indicating systematic biases or errors in the photometric redshift estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568a7bab-7812-42d3-b9b6-388cc87fecaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(ztrue_data.data['redshift'],output_pdfs.data.ancil['zmode'],s=1,c='k',label='simple fzboost mode')\n",
    "plt.plot([0,3],[0,3],'r--')\n",
    "plt.xlim([0,3])\n",
    "plt.ylim([0,3])\n",
    "plt.xlabel(\"specz\")\n",
    "plt.ylabel(\"photoz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e61ccc-900e-444c-8633-3074e4ecc418",
   "metadata": {
    "tags": []
   },
   "source": [
    "### QQ Plot\n",
    "\n",
    "The histogram of PIT values is a useful tool for a qualitative assessment of PDFs quality. It shows whether the PDFs are:\n",
    "* biased (tilted PIT histogram)\n",
    "* under-dispersed (excess counts close to the boudaries 0 and 1)\n",
    "* over-dispersed (lack of counts close the boudaries 0 and 1)\n",
    "* well-calibrated (flat histogram)\n",
    "\n",
    "Following the standards in DC1 paper, the PIT histogram is accompanied by the quantile-quantile (QQ), which can be used to compare qualitatively the PIT distribution obtained with the PDFs agaist the ideal case (uniform distribution). The closer the QQ plot is to the diagonal, the better is the PDFs calibration. \n",
    "\n",
    "The black horizontal line represents the ideal case where the PIT histogram would behave as a uniform distribution U(0,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda1bce2-63d2-436a-93c6-09782a840cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pit_qq(output_pdfs.data.objdata()['yvals'], output_pdfs().metadata()['xvals'].ravel(), ztrue_data()['redshift'], title=\"PIT-QQ plot\", code=\"FlexZBoost\", pit_out_rate=pit_out_rate, savefig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e64c30-5523-4c6b-8733-39a96c732328",
   "metadata": {
    "tags": []
   },
   "source": [
    "### KS plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f483dfa5-f673-4f0d-b63d-c11dc4d3f44c",
   "metadata": {},
   "source": [
    "The two lines represent the CDFs of two distributions:\n",
    "\n",
    "- The red line (\"uniform\") represents the CDF of a uniform distribution, which is the reference or ideal model.\n",
    "- The blue line (\"sample PIT\") represents the CDF of the model predictions or the Probability Integral Transform (PIT) values.\n",
    "\n",
    "In this graph max indicates the maximum difference between the two CDFs. It is a measure of the discrepancy between the predicted distribution and the ideal uniform distribution. In the graph, this difference is highlighted by the black arrow labeled.\n",
    "\n",
    "The KS value on the graph quantifies the distance between the two cumulative distributions. A smaller KS value indicates that the two distributions are closer to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bfaeb6-76e5-4ca8-9c43-362256270c49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ks_plot(pitobj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4f46d4-ab73-4f93-ab86-92d0cf7587bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Summarized Metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7ccd16-3475-400b-8d17-62268203b853",
   "metadata": {},
   "source": [
    "\n",
    "RAIL evaluate metrics that guarantee quality of the processed data, its subdivided in PIT metrics, based on the CDF of the generated photozs described in (Schmidt et al., 2020), CDE metrics, based on the cumulative density function of the MISSING WORDS HELP and the point metrics statistic better disposed in the table:\n",
    "\n",
    "| metric            | classification |limits | reference |\n",
    "| :---------------- | :----:|:----: | :-------: |\n",
    "| STD DEV     | POINT Metric | < 0.05(1 + zphot) |  [Schmidt et al., 2020](http://doi.org/10.1093/mnras/staa2799)| \n",
    "| BIAS              | POINT Metric | < 0.003    | [Schmidt et al., 2020](http://doi.org/10.1093/mnras/staa2799)          | \n",
    "| OUTRATE | POINT Metric | < 10% | [Schmidt et al., 2020](http://doi.org/10.1093/mnras/staa2799)        | \n",
    "| CDE loss          | CDE metric | lower the better | [Izbicki & Lee, 2017](https://arxiv.org/abs/1704.08095) |\n",
    "| PIT               | PIT Metric |prox de 1 | [Polsterer et al., 2016](https://arxiv.org/abs/1608.08016) |\n",
    "| AD | PIT Metrics | lower indicates a uniform PIT | [Schmidt et al., 2020](http://doi.org/10.1093/mnras/staa2799) |\n",
    "| CVM | PIT Metrics | lower indicates a uniform PIT | [Schmidt et al., 2020](http://doi.org/10.1093/mnras/staa2799) |\n",
    "| KS | PIT Metrics | lower indicates a uniform PIT | [Schmidt et al., 2020](http://doi.org/10.1093/mnras/staa2799) |\n",
    "\n",
    "\n",
    "\n",
    "Note that this preliminary metrics proposed performance has been shown to be achievable for simulated LSST data with existing photo-𝑧 estimators (e.g., Graham et al., 2018;\n",
    "Schmidt et al., 2020).\n",
    "\n",
    "Based on the science use-cases described in Appendix C of the [DMTN-049](https://dmtn-049.lsst.io/), the Object catalog photo-zs could have a point-estimate accuracy of 10 % and still meet the basic science needs. The photo-zs results should result in a standard deviation of 𝑧true − 𝑧phot of 𝜎𝑧 < 0.05(1 + 𝑧phot) , and a catastrophic outlier fraction of 𝑓outlier < 10%, over a redshift range of 0.0 < 𝑧phot < 2.0 for galaxies with 𝑖 < 25 mag galaxies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e1fc96-77c8-4a80-a073-8749fb129110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"STD DEV: \", results_df['point_stats_iqr'][0])\n",
    "print(\"BIAS: \", results_df['point_bias'][0])\n",
    "print(\"OUTRATE: \", results_df['point_outlier_rate'][0])\n",
    "print(\"PIT: \", pit_out_rate)\n",
    "print(\"CDE loss: \", cde_stat_and_pval.statistic, \" p-value: \", cde_stat_and_pval.p_value)\n",
    "print(\"AD: \", ad_stat_crit_sig.statistic, \" p-value: \", ad_stat_crit_sig.pvalue)\n",
    "print(\"CVM: \", cvm_stat_and_pval.statistic, \" p-value: \", cvm_stat_and_pval.pvalue)\n",
    "print(\"KS: \", ks_stat_and_pval.statistic, \" p-value: \", ks_stat_and_pval.pvalue)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rail_env",
   "language": "python",
   "name": "rail_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
